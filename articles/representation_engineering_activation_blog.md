---
title: "LLMの内部表現を読んで・操る最新研究に関する論文を一緒に読みましょう！"
emoji: "✨"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["LLM","ActSteering","Representation", "Engineering","Interpretability"]
published: True
---

# Representation Engineering入門：LLMの“内部表現”を読んで・操る最新サーベイ（課題つき）
> この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと**同じ目線**で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！

 

# TL;DR
- **Representation Engineering（RE）**は、LLM内部の**高次概念の表現**（truthfulness, harmfulness, style など）を**読み取り（Reading）**、必要に応じて**介入（Control）**して**ふるまいを直接制御**する枠組みの総称。機構解釈の“ボトムアップ”に対し、**“トップダウン”で高次表現を扱う**のがコア発想。
- 本サーベイは RE の**目的・理論（線形表現仮説／重ね合わせ仮説）**・手法（LAT, Probing, CAA/ActAdd/ITI/Task Vectors ほか）・**評価と副作用**・**研究課題**を体系化。**安全・パーソナライゼーション・性能・真実性**にまたがる応用を横断整理。
- **課題**は「標準評価の欠如」「一般化と多目標同時制御」「強い線形性仮説の未確立」「多モーダルへの展開」「倫理・デュアルユース」。実務上は**介入強度・層・トークン選択**の最適化と**流暢さ劣化の監視**がカギ。



# 背景
## なぜ今「Representation Engineering（RE）」か

* **LLMは強力だが“黒箱かつ制御が難しい”**
  巨大化と高度化で性能は伸びた一方、**内部で何が起きているかの可視化・制御は困難**という課題が増大。現在のSOTA規模では**検証可能な制御や編集が難しい**ことが問題意識として置かれている。
* **REの発想：対照刺激で“高次概念の表現”を見つけて、直接いじる**
  例えば「誠実さ」「無害性」「権威追求」などの**高次概念**を、**コントラストな入力で活性差として捉え**、その**内部表現（方向）を読み取り・編集**して挙動を制御する、というトップダウンな枠組み。

## 既存の解釈法・整列法との立ち位置

* **機構解釈（個々のユニットを下から分解）**に対して、REは**グローバルな活性の差**から**高次概念を同定**し制御する“**トップダウン**”のアプローチだと位置づけている。
* REは二段構え：**Representation Reading（どこに表現があるか特定） → Representation Control（その表現を編集して出力を変える）**。このプロセス自体を図解し、従来のXAIやプロンプト工学、微調整との違いを明確化。

## 理論的な下支え

* **Linear Representation Hypothesis（LRH）**
  多くの高次概念は**活性空間の“ほぼ線形な方向”**として符号化される——という作業仮説。**線形プローブ**や**活性ステアリング**、**ベクトル加算**などが機能する根拠として提示され、NLP/視覚を横断する実証が多数引用されている（ただし **“弱いLRH”の方が根拠が厚い** ）。
  さらに**causal inner product**など、**“意味のある方向”の同定**に向けた理論整理も進んでいるが、**強いLRH（すべて線形）** は未確立だと明言している。
* **Superposition 仮説（重ね合わせ）**
  特徴数が次元数を上回っても**異なる方向の重ね合わせ**で表現される——という仮説。これは**REの有効性を後押し**する一方、**干渉・副作用**（他概念まで変わる、複数介入の予期せぬ相互作用）という**実装上の難しさ**も生むと整理されている。

## なぜサーベイが必要だったか

* **分野横断の“用語・評価・分類”が未整備**
  先行サーベイはXAI全般や機構解釈が主で、**RE自体を体系化した包括サーベイは初**と位置づけ。**手法の分類（Reading/Control・線形/動的強度/複数モデルなど）**、**ベンチマークと指標**、**オープンな課題**を一体で提示する狙いがある。
* **実務的な“副作用・安全・デュアルユース”への懸念**
  介入で**流暢さ低下や計算増**、**ステア強度や層選択の感度**、さらには**安全ガードの反転（逆ステア）**といった**リスク**も整理。**検知と不可逆化**など、**運用・倫理**の論点を早期に標準化すべきだと訴える。

> **巨大で制御しづらいLLMに対し、内部表現という“取っ手”を直接つかんで行動を変える道具箱＝RE**が台頭。
その**理論（LRH/重ね合わせ）・方法（読み取り/介入）・評価・安全**を**横断整理し、課題を提示**すること――これが本サーベイの背景と目的です。



# 理論のベース
- **Linear Representation Hypothesis（LRH）**：高次概念が**活性空間のほぼ線形な方向**として符号化される、という作業仮説。**弱いLRH（いくつかは線形）** には経験的裏付けが厚いが、**強いLRH（すべて線形）** は未確立。**因果内積**など、方向の妥当性を測る理論化が前進中。
- **Superposition 仮説**：特徴数＞次元数でも**方向の重ね合わせ**で表現するため、**干渉や副作用**が起こり得る＝**多重介入や合成**が難しい理由。



# Representation Reading（表現を“見つける”）

* **目的**：LLM内部の活性から、ある**概念/タスク/機能**に対応する表現（方向・部分空間）を特定する段階。概念＝truthfulness等の静的特性、タスク＝特定質問の遂行、機能＝コード生成や多言語応答のような動的特性。
* **コア発想（LAT）**：対照刺激（例：真実/虚偽）で**活性差**を作り、**線形モデル（線形プローブ/PCA）** で方向を抽出する。テンプレで刺激→活性収集→差分→主成分抽出→（必要なら）投影操作まで定式化。
* **Probing**：隠れ状態→ターゲット属性を当てる**監督付き/なしのプローブ**で、モデルが実際にその特徴を**使っているか**を**因果介入**で確かめる流儀。
* **ブラックボックス診断にも**：介入自体はホワイトボックスを要するが、**リーディングはブラックボックスの性能予測や有害モデル検知**にも応用可。
* **設計パラメータと落とし穴**：刺激の**数/選び方**が効く。例：1ペア（ActAdd）〜数千の例まで報告がばらつき、**スプリアス相関**で“本当に望む概念”ではない方向を掴む危険がある。



# Representation Control（表現を“操る”）

* **目的**：Readingで見つけた方向を使い、**推論時に層間へベクトルを注入**して出力を所望の方向へ誘導。基本は **$R' = R + \alpha v$**（強度$\alpha$を調整）。&#x20;
* **単一/多目標**：一方向（例：真実性↑）は容易だが、**複数方向の同時ステア**は難しく、**層を分散**して入れる方が安定という報告。&#x20;
* **介入場所の分類（Table 1 付記）**：全活性\[A]、注意\[AA]、残差流\[R]、MLP\[T]、特定ニューロン\[N]、重み改変\[M]。

## 代表的な“操り方”

* **線形・固定強度（Linear Fixed）**

  * **CAA**：対照刺激の**平均差**を残差流に加算（迎合/拒否/訂正性の制御）。層間一貫性や移植性あり
  * **RepE（PCA系）**：LATで読んだ方向をそのまま**足し引き**（Reading/Contrast両様）
  * **ITI**：**“真偽に効く注意ヘッド”だけ**動かす**ヘッド限定介入**，ヘッド数と強度で微調整
  * **ActAdd**：**1ペア**でも差ベクトルで即介入
  * **LSV**：勾配で最適化した**固定長ベクトル**を中層中心に注入

* **動的強度（Dynamic Strength）**

  * **ACT**：真実性に応じて**強度を自動調整**し、幻覚クラスタごとに別ベクトルを当てる
  * **RE-CONTROL**：**価値関数で制御信号**を最適化し、生成中に柔軟介入
  * **Activation Scaling**：既存の加算ベクトルと違い、学習された乗数（スカラー）で活性の大きさだけを増減させる方式（SteerVec/ActivScalar）

* **幾何変換・構造化**

  * **HPR**：ハウスホルダー反射ベースの**回転近似**でノルム一貫性を保ちつつ編集。
  * **Conceptors**：**楕円体へのソフト射影**で機能タスクを改善、**AND/OR**で複数目標も合成．




# 応用の4象限
- **Truthfulness（幻覚抑制）**：truth 方向の増幅や選択的介入で**嘘の尤度を下げる**。
- **Security（有害出力防止／赤組）**：**安全方向**の抽出・注入、**回路遮断**、**概念転写**。逆に**安全除去の実証**もあり**デュアルユース**性が高い。
- **Personalization**：**スタイル／価値観**の多様化を**微小介入で実現**。**複数ベクトルの合成**は要注意。
- **Performance**：Task Vectors/SCANS/EAST などで**狙い撃ちの性能改善**（CoT, コード, 選択的探索など）。



# 評価：何を測るべきか（落とし穴つき）
- **開放生成での有効性**：多肢選択だけだと効いて見えても、**自由生成では崩れる**ことがある。**トークン確率・因果検証**も合わせる評価パイプラインを推奨。
- **流暢さ（副作用）**：介入が強すぎると**意味連続性の崩壊・確率分布の歪み**が起こるため、**強度・層・トークン選択**の調整が必須。



# 研究課題（Open Problems）
1. **標準評価の欠如**：データセット・指標・設定がバラバラ。**開放生成＋尤度＋因果検証**の標準化が必要。
2. **理論の未整備**：LRH の適用範囲、**最適層・強度**の理論導出、**干渉解析**が未成熟。
3. **一般化と反作用**：**反ステア（逆効果）例**や**O.O.D.**で効かないケースの体系理解。
4. **マルチモーダル展開**：**トークナイズ／量子化の非連続性**、**方向の意味解釈**、**非線形相互作用**への対処。
5. **倫理・デュアルユース**：**安全ガードの剥離**・**属性偏りの増幅**の危険。**検知・不可逆化**の研究が重要。



# まとめ
- **RE は“LLMの内部表現を直接いじる”実践的な上位概念**。**軽量・即効**で、**整列・安全・個人化・性能**に効くが、**評価と理論、複合制御**は未成熟。  
- **当面の最適解**は：**小さく読む→中間層に薄く効かせる→副作用を多視点で検査**。**標準化された評価パイプライン**が次の鍵。



# 参考（論文情報）

- **タイトル**：*Representation Engineering for Large-Language Models: Survey and
Research Challenges*
- **著者**：Lukasz Bartoszcze, Sarthak Munshi, Bryan Sukidi, Jennifer Yen, Zejia Yang, David Williams-King, Linh Le, Kosi Asuzu, Carsten Maple
- **年**：2025
- **arXiv**： [2502.17601v1](https://arxiv.org/abs/2502.17601v1)