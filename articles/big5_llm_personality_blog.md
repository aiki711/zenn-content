---
title: "BigFiveに基づく対話データセットを使ったLLMの性格傾向学習に関する論文を一緒に読みましょう！"
emoji: "😺"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["LLM","NLP","Alignment","Personality","DPO"]
published: false
---

# BIG5-CHAT: 人間由来データでLLMのパーソナリティを“訓練で”形づくる
> この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと**同じ目線**で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！



# TL;DR
- **何をした？** Big Five（ビッグファイブ）に基づく**10万件**の対話データセット *BIG5-CHAT* を作成し、SFTとDPOで**性格傾向を訓練で付与**。プロンプト注入より妥当で人間らしい特性表現を実現。 
- **何が効いた？** 特にSFTが有効。**高い勤勉性・協調性、低い外向性・神経症傾向**のモデルは推論系ベンチで好成績。心理学の知見とも概ね整合。
- **なぜ重要？** 「その人らしさ」を**行動文の指示ではなく**、人間由来の言語パターンから学習。性格×性能の関係性も可視化し、**タスク適合な“性格チューニング”**の道を開く。 



# 背景と課題設定
従来は「あなたはパーティーの主役です」のような**行動記述をプロンプトに入れる**方式が主流だったが、LLMにとって非現実的（“パーティーに行かない”）かつ**評価妥当性**にも課題があった。大規模な**人間生成データ×性格注釈**の不足も、学習ベース手法の探索を阻んでいた。 
また、性格特性が注釈付けされた大規模な人間生成データセットが不足しているため、学習ベースのアプローチの探索が妨げられていた．
役割ベースのプロンプトがLLMの推論パターンを不均衡に、または過度に制約する可能性がある．


# 研究の貢献
1. **BIG5-CHAT**: ビッグファイブ5特性×高/低で**10万対話**（各特性2万、H/L半々）。SODAの多様な社会場面を土台に、同一コンテキストで**性格レベルのみを切り替えた**ペア対話を構築。
2. **学習での性格付与**: **SFT**と**DPO**を適用し、**プロンプト不要**で性格パターンを生成に反映。BFI/IPIP-NEO評価でプロンプトより良好な相関を獲得。 
3. **性格と推論性能の関係**: 勤勉性/協調性↑、外向性/神経症傾向↓のモデルが**推論系ベンチで高成績**。心理学の知見とも概ね一致。



# データセットの作り方（BIG5-CHAT）
- **ベース**: SODA（社会常識が濃い多様なシナリオ）を10,000件サンプリング。
- **性格注入**: **PSYCHSTEER**フレームワークで、ベースモデルが最初の5語を出した後、**エキスパート生成器**（特性別にSFT済み）で**ロジット補正**して望ましい特性へ誘導。
- **対話生成**: 同一コンテキストに対して**高/低レベル双方**の応答を生成し、**特性のみ**を変える。最終的に**100,000**単発応答（5特性×高低×各1万）。 



# 手法のポイント（ざっくり）
- **DExperts系の誘導**: 特性ごとの“エキスパート”で**出力ロジットを調整**し、特性一貫性と自然性を維持。
- **学習レシピ**: エキスパート生成器は**Alpaca形式**でSFT。生成時は**5語ウォームアップ→ロジット補正**で性格を制御。 



# 評価設定と主な結果
- **パーソナリティ妥当性**: BFI / IPIP-NEOで**訓練ベース（SFT/DPO）がプロンプトを上回る**。 
- **タスク性能（LLaMA-3系）**:  
  - **70B**: 平均的に**SFTが最良**。勤勉性・協調性が**高い**、外向性・神経症傾向が**低い**ほど**社会/数理/常識推論**で有利。  
  - **8B**: ベンチ種別ごとの挙動を詳細報告（表13）。数学では**高い開放性×DPO**が効く一方、常識推論では一貫しないなど**タスク依存性**も観測。

> まとめると、**“性格のチューニング”が（少なくとも一部の特性では）推論系能力にも波及**し得る。ただし**開放性は数学以外では限定的**という**領域特異性**も示唆。 



# 考察：なぜ“学習ベース”が効くのか
- **行動記述ではなく言語パターン**を学習するため、**テキスト内の一貫した語用論・語彙選好**が再現されやすい。  
- **プロンプト注入の過剰・非現実性**を回避し、**評価（BFI/IPIP-NEO）との整合**が高まる。 
- **性能影響のヒント**: 勤勉性・協調性は**系統立て方/衝突回避**に効き、外向性・神経症の低さは**注意散漫や不安定さの抑制**として現れる可能性。実験結果は心理学のメタ知見とも概ね整合。



# 倫理・限界・今後
- **バイアス継承のリスク**: 人間生成データに由来する**社会的ステレオタイプ**や**不適切行動**の学習可能性。論文でも**特定特性のシナリオ出力に偏り**の例示あり。 
- **評価カバレッジ**: 本研究の**性格×推論**分析は**限られたタスク文脈**に依存。より広範な設定での一般化検証が必要。 
- **単一特性の前提**: 本稿は**単一特性の独立操縦**にフォーカス。実際の人格は**多特性の相互作用**で発現するため、**マルチトレイト操縦**（複数エキスパートの合成や結合学習）は今後の重要テーマ。  
- **フレームワーク自体の限界**: ビッグファイブは広く妥当だが**全ての文化・集団の多様性を網羅しない**。学習元データの**年齢/英語/ネット利用**などの偏りも指摘。 



# 使いどころ（実務の観点）
- **顧客対応/教育/支援**: タスクに応じて**“勤勉性・協調性高め”の性格プリセット**を選ぶことで、**安定した推論・説明**を引き出す設計が可能。 
- **安全策**: デプロイ前に**特性別の出力監査**（毒性・ステレオタイプ・不安誘発など）を。**人間由来データの偏り**を可視化し、**修正ループ（データ/報酬/ポリシー）**を組み込む。 



# まとめ
- **BIG5-CHAT**は、人間らしい性格表現を言語から学習させるための**実用的コーパス**。  
- **SFT/DPOによる学習ベースの性格付与**は、プロンプトよりも**妥当かつ一貫**。一部特性では**推論性能の向上**も確認。
- ただし**倫理・分布偏り・評価範囲**には注意。**多特性の合成**と**広範な一般化検証**が次の課題。



# 参考（論文情報）

- **タイトル**：*Steering Llama 2 via Contrastive Activation Addition*
- **著者**：Nina Rimsky, Nick Gabrieli, Julian Schulz, Meg Tong, Evan Hubinger, Alexander Matt Turner
- **年**：2024
- **arXiv**： [2312.06681v3](https://arxiv.org/abs/2312.06681v3)