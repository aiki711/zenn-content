---
title: "長期対話を“イベント記憶×ペルソナ”で支える LLMに関する論文を一緒に読みましょう！"
emoji: "👋"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["LLM", "Dialogue", "RAG", "Memory", "Persona"]
published: false
---


# LD-Agent: 長期対話を“イベント記憶×ペルソナ”で支える LLM パーソナライズド・エージェント
> この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと**同じ目線**で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！


# TL;DR
- **LD-Agent** は長期・マルチセッション対話のための**モデル非依存**フレームワーク。①**イベント知覚**（長期/短期メモリ）、②**ペルソナ抽出**（ユーザ/エージェント双方）、③**応答生成**の3モジュールで構成し、取得したメモリとペルソナを統合して応答を誘導します。:contentReference[oaicite:0]{index=0}  
- **長期メモリ**は要約をベクトル化して記憶、**トピック（名詞）重なり＋時系列減衰**を併用する**トピック型リトリーバ**で想起精度を上げます。短期メモリは現在セッションのキャッシュ。:contentReference[oaicite:1]{index=1} :contentReference[oaicite:2]{index=2}  
- **MSC / Conversation Chronicles** の2ベンチで SOTA。**ChatGPT/ChatGLM/BlenderBot/BART** 等、LLM/非LLM・ゼロショット/チューニング問わず一貫して上振れ。**HAHT** を同規模で上回るケースも。:contentReference[oaicite:3]{index=3} :contentReference[oaicite:4]{index=4}  
- **汎用性**：クロス**ドメイン**（MSC↔CC）でも高水準、**マルチパーティ対話**（Ubuntu IRC）にも転用可。:contentReference[oaicite:5]{index=5} :contentReference[oaicite:6]{index=6}  
- **コード公開**あり（GitHub）。:contentReference[oaicite:7]{index=7}



# 何が新しい？（貢献）
- **長期イベント×人物像の“両輪”を明示分離し統合**：イベント要約＋メモリ想起と、ユーザ/エージェント双方の動的ペルソナ抽出を**独立チューニング可能**なモジュールに分解。:contentReference[oaicite:8]{index=8}  
- **トピック型リトリーバ**：従来の埋め込み類似に、**名詞ベースのトピック重畳＋時間減衰**を足して“取り違い”を抑制。:contentReference[oaicite:9]{index=9}  
- **モデル非依存・現実的**：LLM/非LLMの**上に載せるだけ**で長期対話能力を底上げ。ゼロショット/チューニング両設定で効果。:contentReference[oaicite:10]{index=10}



# 手法（LD-Agent 概観）

* **タスク定義**：現在セッション $C$ と履歴 $H$ から適切応答 $r$ を生成（長期×短期の両方を利用）。

## イベント知覚（長期/短期メモリ）

* **長期メモリ**：過去セッションの**要約と時刻**をテキストエンコーダ（例：MiniLM）で表現し低コスト・バンクに格納 $M_L=\{\phi(t_j,o_j)\}$。要約器は **DialogSum** を再構成して**指示微調整**。
* **想起（Retrieval）**：**語義類似 $s_{sem}$**＋**名詞セット重なり $s_{top}$**＋**時間減衰 $\lambda_t=e^{-t/\tau}$**。さらに**語義スコア閾値 $\gamma=0.5$** でノイズ除去。
* **短期メモリ**：現在セッションをキャッシュ。**最終記録から600秒超**なら長期要約を更新し、短期はクリア。

## ペルソナ抽出（ユーザ/エージェント）

* **MSC 由来の発話単位データ**を作成し、抽出器を**LoRA 指示調整**。ゼロショット CoT 併用も可。抽出結果は\*\*“No Trait”\*\*含めてバンクに更新。

## 応答生成

* 取得メモリ $m$、短期文脈 $M_S$、ユーザ/エージェントのペルソナ $P_u,P_a$ を**統合プロンプト**に入れて生成器 $G$ に投入：
  $r = G(u′, m, M_S, P_u, P_a)$。学習用に**動的にモジュールを回しながら**プロンプト化したデータセットを構築。



## データセット / 評価 / ベースライン

* **MSC / Conversation Chronicles（CC）**：各5セッション、サンプルあたり約50ターン。時間間隔メタデータ付き。
* **評価指標**：自動（**BLEU-N, ROUGE-L, METEOR**／抽出器は **ACC**）。人手（**Coherence/Fluency/Engagingness**）。
* **ベースライン**：**ChatGPT/ChatGLM**（LLM）、**BlenderBot/BART**（非LLM）、従来 SOTA **HAHT**。`ModelLDA` は **LD-Agent を組み込み**。



# 主な結果

* **長期対話 SOTA**：MSC/CC いずれも、**LD-Agent 組込みが全セッションで有意に改善**。ChatGPT/ChatGLM（ゼロショット）や BlenderBot（チューニング）でも一貫して上振れ。**HAHT** も同規模で凌駕。
* **アブレーション**：**イベントメモリの寄与が最大**。セッションが進んでも性能の落ち込みが**最も緩やか**。
* **抽出器の比較**：**LoRA 調整抽出器 > ゼロショット CoT**（抽出 BLEU/R-L/ACC、生成への波及も向上）。
* **人手評価**：**トピック型リトリーバ**が**直の語義類似**より ACC/Recall で優位。**応答の Coherence/Fluency/Engagingness**も LD-Agent が上。
* **クロスドメイン**：MSC↔CC の入替でも**ゼロショットを大幅超え**、同ドメイン学習に**肉薄**。
* **クロスタスク**：**Ubuntu IRC**（マルチパーティ対話）に移植した **BARTLDA** が既存手法を上回る。


# 限界と今後

* **実世界データ不足**：現行の長期対話データは**人手/LLM 生成の疑似**が中心。実データでの検証が課題。
* **モジュール設計の深化余地**：長期要約・高精度リトリーバ・高度なペルソナ抽出/検索の洗練が次の焦点。



# まとめ（運用メモ）

* **まずは“イベント要約＋トピック型想起＋動的ペルソナ”を最小構成で**。既存ボットに**載せ替えるだけ**で長期一貫性が伸びる。
* **評価は自動＋人手の併用**（特に**Coherence across sessions**）。**抽出器は LoRA 調整推奨**。

> 付録（任意）：Table/図の再描画、プロンプト雛形（要約/抽出/生成）は Appendix D を参照して図示すると読者に親切です。
