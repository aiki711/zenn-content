---
title: "ペルソナベクトルの抽出と制御・監視に関する論文を一緒に読みましょう！"
emoji: "🍣"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["LLM","Personality","Communication","Psychology","AI Ethics"]
published: True
---

# Persona Vectors: Monitoring and Controlling Character Traits in Language Models を噛み砕く

> この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと**同じ目線**で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！


# TL;DR（最初に結論）

* LLM の内部表現には，「悪意（evil）」「迎合（sycophancy）」「ハルシネーション傾向」などの“人格特性”に対応する**ペルソナベクトル**が潜在している．
* その方向を使うと，

  1. 生成開始 **前** にプロンプトで人格が崩れる兆候を **監視**，
  2. 微調整（fine-tuning）で望ましくない人格の **シフトを測定・予測**，
  3. 生成時の **事後ステアリング** や学習中の **予防ステアリング** による **制御**
     が可能になります．
* さらに学習データを **“危険度”でふるいにかける（射影差）** こともできる．



# はじめに - なぜ「人格特性に対応する方向ベクトル」に着目したのか

* LLM は「アシスタント」という人格（persona）を模して応答しますが，
  * プロンプトの影響や
  * 微調整や継続学習の副作用によって，時に **悪意（攻撃性）**・**迎合（過度な同意）**・**ハルシネーション傾向** などに **滑る（drift）** など
ときどき望ましくない振る舞いに逸脱する．

* 著者らは「悪意（evil）」「迎合（sycophancy）」「ハルシネーション傾向」などの特性に対応する**ペルソナベクトル**をモデルの活性空間から抽出し，
  1. こうした人格の揺らぎを**観測**でき，
  2. 学習（微調整）で生じる人格変化を**予測**・**制御**できる
という仮説を立てた．

* 本論文は，**線形方向ベースの実用的フレームワーク** を提示している．



# 何をした論文か（貢献）

* 任意の自然言語で記述された“特性”から，**自動**で persona vector を抽出するパイプライン．
* **監視**：生成直前のプロンプト活性を特性方向に射影し，「今から逸脱しそうか」をスコア化．
* **制御**：

  * 生成時に $\pm \alpha v_\ell$ を加える **事後ステアリング**（悪化/抑制），
  * 学習過程に方向を入れて偏りを打ち消す **予防ステアリング**（能力劣化を抑えやすい）．
* **データ審査**：特性方向への **射影差（projection difference）** により，

  * データセット単位・サンプル単位で「人格シフトを招きやすい」危険データを **事前にフラグ** 可能．

微調整後の意図的・非意図的な人格変化は，該当する persona vector 方向への活性シフトと強く相関する．
こうしたシフトは，生成時の**事後介入**で緩和でき，さらに学習過程での**予防的ステアリング**でそもそも回避することも可能である．
さらに persona vectors を使うと，**データセット単位／サンプル単位**で“望ましくない人格変化を招きやすい学習データ”を**事前にフラグ**できる．
また，ベクトル抽出は自動化されており，**自然言語の特性記述さえあれば**任意の人格特性に適用できる．



# 手法の全体像

![パイプライン](/images/llm_personality_reserch_blog/figure1.png "Persona vectors and their applications.")

1. **特性記述**（例：「evil: 攻撃性・悪意を示す応答傾向」）
2. **対照プロンプト生成**：特性を促す/抑える *system prompt* と評価用 *question* を自動生成
3. **多数応答生成 & ジャッジ**：各応答に“特性スコア”を付与（LLM ジャッジ等）
4. **活性差から方向抽出**：応答トークンの残差活性平均の差 = persona vector
5. **用途**：監視／制御（事後・予防）／データ審査（射影差）



# 数式メモ（最小限）

**記法**：層 $\ell$ の残差活性を $h_\ell(x,t)$（トークン $t$）とし，応答トークンで平均：
$$
\bar{h}_\ell(x)=\frac{1}{T}\sum_{t=1}^T h_\ell(x,t)
$$

特性“有り/無し”の集合 $X^+,X^-$ に対し，**persona vector**：
$$
 v_\ell=\mathbb{E}_{x\in X^+}[\bar{h}_\ell(x)]-\mathbb{E}_{x\in X^-}[\bar{h}_\ell(x)]
$$

**監視スコア（生成前）**：直前プロンプトのラストトークン活性 $\tilde h_\ell(p)$ に対し
$$
 s(p)=\langle \tilde h_\ell(p),\, v_\ell\rangle
$$

**事後ステアリング（生成時）**：
$$
 h'_\ell(x,t)=h_\ell(x,t)+\alpha\,v_\ell \quad(\text{抑制は }\alpha<0)
$$

**射影差（データ審査）**：候補データ応答とベースモデル自然応答の投影差
$$
 \Delta P=\langle \mathbb{E}[\bar{h}_\ell(\text{candidate})],v_\ell\rangle-\langle \mathbb{E}[\bar{h}_\ell(\text{base})],v_\ell\rangle
$$



## Persona Vector 抽出（詳細）

![抽出フロー](/images/llm_personality_reserch_blog/figure2.png "Automated pipeline for persona vector extraction.")

1. **対照条件の用意**：特性を「促す／抑える」2種の system prompt を自動生成．
2. **応答生成**：同一質問に対して両条件で多数の応答を作成．
3. **ジャッジ**：各応答に LLM 判定で特性スコア（連続 or バイナリ）を付与．
4. **活性収集**：対象層の残差活性を**応答トークン平均**で集計．
5. **方向推定**：上の式から $v_\ell$ を算出し，検証で最も効いた層 $\ell$ を採用．



## 制御（Steering）

![事後/予防ステアリング](/images/llm_personality_reserch_blog/figure3.png)
hℓ←hℓ−α⋅vℓ​．ここでαはステアリング係数，𝑣ℓは抽出したペルソナベクトル，hℓは層ℓにおける残差ストリーム活性である．
図7Aは，複数モデル・複数特性にわたり，係数を大きくするほど対象特性の表出が大きく低下することを示す

### 事後ステアリング（生成時）

* 生成ループ中に $h_\ell \leftarrow h_\ell + \alpha v_\ell$ を適用．
* **強める**：$\alpha>0$，**弱める**：$\alpha<0$．
* **利点**：外付けで即適用・撤去が容易．
* **注意**：$|\alpha|$ を大きくしすぎると\*\*一般能力（例：MMLU）\*\*が落ちやすい．

### 予防ステアリング（学習中）

* 学習時に $+\beta v_\ell$ を加えて“偏り圧”を相殺，または
  **正則化** $\mathcal{L}_{\text{persona}}=\lambda\langle \bar{h}_\ell, v_\ell\rangle^2$ を損失に追加．
* **目的**：**人格シフトを小さく**保ちつつ，**能力劣化を抑える**．



## 監視（Monitoring）

![監視概念図](/images/llm_personality_reserch_blog/figure5.png)

図5は，many-shot 設定における本手法のモニタリング有効性を示している．各評価質問の先頭に，目標特性を明示的に示す少数例（0/5/10/15/20個）を付与したところ，最終プロンプトトークンの活性をペルソナベクトルへ射影した値が，その後に生成される応答の特性表現スコアと強く相関した．横軸が射影値，縦軸が特性スコアであり，few-shot 例の数を増やすほどスコアが上昇する傾向が確認できる．

* **応答生成前**：ユーザ最終プロンプトの**最後のトークン活性**を $v_\ell$ に射影してスコア化．
* **応答生成後**：応答の特性表現スコアは後続の**特性スコアと高い相関**（概ね $r\approx0.75\text{–}0.83$）が報告される．



## 人格シフトの測定（微調整の影響）

![微調整シフトと表現スコアの関係](/images/llm_personality_reserch_blog/figure6.png)

図6は，ペルソナベクトルに沿った微調整シフトと，対応する特性の表現スコアとの関係を示している

* 特性方向への**活性シフト量（finetuning shift）**は，学習後の**特性表出**と高相関（$r=0.76\text{–}0.97$）．
* 特性を狙っていない **EM-like**（例：医療の誤助言，誤ったコード／数理解法）でも**意図せぬ人格変化**を誘発し得る．



## データ審査：投影差で“危険”を弾く

![投影差の概念図](/images/llm_personality_reserch_blog/figure4.png)

図4は対照の教師応答の射影と特性を強く反映させた教師応答の射影の分布を比較．
教師応答というのは，外部の大規模言語モデルによって，対照の応答と特性の強さを変えた応答を生成させて作成している．

* スコア分布を**Normal vs. II（性向強・欠陥強）**で比べると，明確に分離していることがわかる．

また，射影差からデータ学習後の振る舞いを予測できる．
* 教師応答yi＝「モデルに学習で模倣させたい“答え”」で，ベース応答yi′＝「学習なしでモデルが自力で出す答え」を用いて，**射影差** $\Delta P$ を計算．
* $\Delta P$ が大きいほど，その特性方向に**引っ張る危険サンプル**．



# 既知の限界・注意点

* **LLMジャッジ**（GPT-4.1-mini）に依存 → 人手評価や外部ベンチで妥当性チェックはしているが，評価者バイアスには注意．
* 監視の相関は**プロンプト条件の違い**で主に生じる（微妙な変化検出は弱まる）．
* 特性間の**相関**（負の/正の連動）も観測 → 単一特性だけを独立に動かすのは難しい，一方を抑えると別が強まる等の連動があり得る．
* 事後ステアリングは**能力低下**の副作用があり得る一方，予防ステアリングは**多層**でより有効．



# 参考（論文情報）

- **タイトル**：*Persona Vectors: Monitoring and Controlling Character Traits in Language Models*
- **著者**：Runjin Chen, Andy Arditi, Henry Sleight, Owain Evans, Jack Lindsey
- **年**：2025
- **arXiv**： [arXiv:2508.08222](https://arxiv.org/abs/2507.21509)
