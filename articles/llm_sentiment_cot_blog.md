---
title: "ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ¬¡ã¸ï¼šFew-shotã¨CoTã§æ„Ÿæƒ…åˆ†é¡ã‚’åº•ä¸Šã’ã™ã‚‹ï¼ˆIMDBï¼‹vLLMï¼‰"
emoji: "ğŸ§©"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["AI","LLM","NLP","CoT","Prompting"]
published: false
---


# LLMæ„Ÿæƒ…æ¨å®šã®ç¶šç·¨ï¼šFew-shotã¨CoTã§å®‰å®šæ€§ã¨ç²¾åº¦ã‚’åº•ä¸Šã’ã™ã‚‹

**â€” ä¾‹ç¤ºï¼ˆFew-shotï¼‰ã¨Chain-of-Thoughtã€å¤šæ•°æ±ºãƒ»æŠ•ç¥¨ç‡confidenceã€JSONãƒ‘ãƒ¼ã‚¹ã¾ã§ â€œå£Šã‚Œãªã„â€ æ¯”è¼ƒå®Ÿé¨“ â€”**

*æ›´æ–°: 2025-08-18 15:00*

## TL;DR

* **Few-shot**ã¯ã€Œåˆ¤æ–­ã®ç‰©å·®ã—ã€ã‚’ç¤ºã›ã‚‹ã®ã§ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã‚ˆã‚Š**å¢ƒç•Œäº‹ä¾‹ã§å®‰å®š**ã—ã‚„ã™ã„ï¼
* **CoTï¼ˆè€ƒãˆã‚‹â†’æœ€çµ‚ã¯JSONã®ã¿ï¼‰**ã¯æ›–æ˜§ä¾‹ã«åŠ¹ãä¸€æ–¹ã€å‡ºåŠ›å´©å£Šã®ãƒªã‚¹ã‚¯ãŒã‚ã‚‹ãŸã‚**â€œJSONã®ã¿â€ã®å¼·åˆ¶**ï¼‹**næœ¬ç”Ÿæˆã®å¤šæ•°æ±º**ã§å …ç‰¢åŒ–ï¼
* **æŠ•ç¥¨ç‡ã‚’confidenceã«æ¡ç”¨**ã™ã‚‹ã¨ã€Œè‡ªå·±ç”³å‘Šã®confidenceã®ç„¡ç›¸é–¢å•é¡Œã€ã‚’å›é¿ã§ãã‚‹ï¼
* ä»˜å±ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆvLLM + IMDBï¼‰ã§ **zero / few(2,5) / cot** ã‚’**åŒä¸€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã§å†ç¾ãƒ»æ¯”è¼ƒå¯èƒ½ï¼


## èƒŒæ™¯ã¨ç›®çš„

å‰å›ã€Œã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆç·¨ã€ã§ã¯ï¼Œ**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â†’ JSONå¼·åˆ¶ â†’ ãƒ‘ãƒ¼ã‚¹ â†’ æŒ‡æ¨™**ã¨ã„ã†æœ€å°æ§‹æˆã‚’ä½œã‚Šï¼Œå£Šã‚Œãšã«å›ã›ã‚‹è©•ä¾¡ã®è¶³å ´ã‚’ç”¨æ„ã—ãŸï¼æœ¬ç¨¿ã§ã¯ãã®è¶³å ´ã®ä¸Šã«**Few-shot**ã¨**CoT**ã‚’ç©ã¿å¢—ã—ï¼Œ**ç²¾åº¦**ã¨**å®‰å®šæ€§**ã®æ”¹å–„ã‚’æ¤œè¨¼ã™ã‚‹ï¼
ç‰¹ã«ï¼ŒCoTã¯**æ€è€ƒã®èª˜å°ã¨æœ€çµ‚å‡ºåŠ›ã®å³æ ¼ã•**ã‚’ä¸¡ç«‹ã•ã›ã‚‹è¨­è¨ˆãŒè‚ã«ãªã‚‹ãŸã‚ï¼Œ**å¤šæ•°ç”ŸæˆÃ—å¤šæ•°æ±º**ï¼‹**æŠ•ç¥¨ç‡confidence**ã‚’çµ„ã¿åˆã‚ã›ã¦ï¼Œè©•ä¾¡ãƒ»è§£æã¾ã§å´©ã‚Œãªã„å½¢ã«æ•´ãˆã‚‹ï¼


## ä½¿ã£ãŸã‚³ãƒ¼ãƒ‰ï¼ˆã–ã£ãã‚Šï¼‰

```
prompts.py                 # Zero / Few-shot / CoT ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆ2/3ã‚¯ãƒ©ã‚¹å¯¾å¿œã®é››å½¢ï¼‰
parser.py                  # å¿œç­”ã‹ã‚‰æœ€åˆã®JSONã‚’æŠ½å‡ºãƒ»æ­£è¦åŒ–ï¼ˆlabelè¡¨è¨˜ã‚†ã‚Œ/ä¿¡é ¼åº¦ã‚¯ãƒªãƒƒãƒ—ï¼‰
run_vLLM_imdb_variants.py  # vLLMã§ IMDB ã‚’ zero / few2 / few5 / cot ã§ä¸€æ‹¬å®Ÿè¡Œï¼†è©•ä¾¡
analyze_cot_quality.py     # CoTã® â€œãƒ‘ãƒ¼ã‚¹ç‡/ç²¾åº¦/å¹³å‡confidence/ç›¸é–¢â€ ã‚’è¦ç´„ï¼ˆâ€»ç’°å¢ƒã«ã‚ˆã£ã¦ã¯ .py.pyï¼‰
report_cot_quality.json    # å®Ÿè¡Œä¾‹ã®ã‚µãƒãƒªãƒ¬ãƒãƒ¼ãƒˆ
```

> å‚™è€ƒï¼š`run_vLLM_imdb_variants.py` ã¯å„ `--variant` ã®æ¨è«–å¾Œã«è©•ä¾¡ã‚’å‘¼ã³å‡ºã—ï¼Œ`report_{variant}.json` ã‚’ `--outdir` é…ä¸‹ã«ä¿å­˜ã™ã‚‹æ§‹æˆï¼


## å®Ÿé¨“è¨­è¨ˆ

### ã‚¿ã‚¹ã‚¯

* **2ã‚¯ãƒ©ã‚¹**ï¼šIMDBï¼ˆpositive / negativeï¼‰
* **3ã‚¯ãƒ©ã‚¹**ï¼špositive / neutral / negativeï¼ˆå°†æ¥æ‹¡å¼µï¼‰

### å…±é€šã®å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒï¼ˆLLMã®å›ç­”ã¯**å¿…ãšã“ã‚Œã®ã¿**ï¼‰

```json
{
  "label": "positive|neutral|negative",
  "confidence": 0.0_to_1.0,
  "reason": "æ ¹æ‹ ã®çŸ­æ–‡"
}
```

### Few-shot ã®ç‹™ã„

* å…¸å‹ä¾‹ã‚’æ•°ä»¶ç¤ºã—**å¢ƒç•Œã®åŸºæº–**ã‚’å…±æœ‰ï¼ˆçš®è‚‰ãƒ»å¼±ã„æ„Ÿæƒ…ãƒ»æ›–æ˜§è©•ä¾¡ã®å–ã‚Šæ‰±ã„ï¼‰
* ä¾‹ã¯**çŸ­ãæ˜å¿«**ã€é›£ä¾‹ã‚’å…¥ã‚Œã™ããªã„ï¼ˆã¾ãšåœŸå°ã‚’ä½œã‚‹ï¼‰

#### Few-shotï¼ˆ2ã‚·ãƒ§ãƒƒãƒˆï¼2ã‚¯ãƒ©ã‚¹ãƒ»è‹±èªä¾‹ï¼‰

```text
You are a strict grader. Follow the examples and classify movie review sentiment into positive or negative.

[Example 1]
Review: "Loved the pacing and the ending."
Output: {"label":"positive","confidence":0.94,"reason":"clear satisfaction"}

[Example 2]
Review: "Waste of time. Wouldn't recommend."
Output: {"label":"negative","confidence":0.95,"reason":"clear dissatisfaction"}

Rules:
- Clear satisfaction/recommendation â†’ positive
- Clear dissatisfaction/complaint/refusal â†’ negative
Output must be only this JSON schema (no extra text / no markdown / no code fences):
{
  "label": "<positive|negative>",
  "confidence": <0.0_to_1.0>,
  "reason": "<one short sentence>"
}

Review:
<text>
```

### CoT ã®ç‹™ã„ã¨æ³¨æ„

* **æ€è€ƒã‚’ä¿ƒã™**ã“ã¨ã§æ›–æ˜§ä¾‹ã®åˆ¤æ–­ã‚’å®‰å®šåŒ–ï¼
* ãŸã ã—**æ€è€ƒæ–‡ãŒæ··ã–ã‚‹å´©å£Š**ã«å‚™ãˆã¦ï¼Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§\*\*â€œæœ€çµ‚ã¯JSONã®ã¿â€\*\*ã‚’å¼·åˆ¶ï¼
* **åŒä¸€ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦ næœ¬ç”Ÿæˆ**â†’**å¤šæ•°æ±ºã§æœ€çµ‚ãƒ©ãƒ™ãƒ«**â†’**vote shareã‚’confidence**ã«ã™ã‚‹é‹ç”¨ãŒå®Ÿå‹™çš„ã«å …ã„ï¼

#### CoTï¼ˆ2ã‚¯ãƒ©ã‚¹ãƒ»è‹±èªä¾‹ï¼š**æœ€çµ‚ã¯JSONã®ã¿**ï¼‰

```text
You are a strict grader. Think briefly inside your head, but DO NOT output your steps.
Output ONLY the final JSON (no extra text / no markdown / no code fences).

Rules:
- Clear satisfaction/recommendation â†’ positive
- Clear dissatisfaction/complaint/refusal â†’ negative

Final JSON schema (reason â‰¤ 12 words):
{
  "label": "<positive|negative>",
  "confidence": <0.0_to_1.0>,
  "reason": "<one short sentence (â‰¤12 words)>"
}

Review:
<text>
```


## å†ç¾æ‰‹é †ï¼ˆIMDB Ã— vLLMï¼‰

### 1) å®Ÿè¡Œ

```bash
# ä¾‹: Mistral-7B-Instruct ã‚’åˆ©ç”¨ã€‚variant ã¯ zero / few2 / few5 / cot ã‚’åˆ‡ã‚Šæ›¿ãˆ
python run_vLLM_imdb_variants.py \
  --model mistralai/Mistral-7B-Instruct-v0.3 \
  --variant cot \
  --num_samples 100 \
  --outdir runs_imdb_variants
```

* æ¨è«–çµæœï¼ˆraw JSONLï¼‰ã¨ gold ãŒ `--outdir` ã«ä¿å­˜ã•ã‚Œï¼Œè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ `report_{variant}.json` ãŒå‡ºåŠ›ã•ã‚Œã‚‹ï¼
* CoTã¯**å„ã‚µãƒ³ãƒ—ãƒ«ã‚’nå›ç”Ÿæˆ**ã—ã¦**å¤šæ•°æ±º**ã—ï¼Œ**æŠ•ç¥¨ç‡ã‚’confidence**ã¨ã—ã¦è¨˜éŒ²ï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå…ˆé ­ã‚³ãƒ¡ãƒ³ãƒˆå‚ç…§ï¼‰ï¼

### 2) å“è³ªã‚µãƒãƒªï¼ˆCoTä¾‹ï¼‰

`report_cot_quality.json`ï¼ˆ100ä»¶, IMDB, CoTï¼‰ã®ä¾‹ã‚’æŠœç²‹ï¼š

```json
{
  "parse_success_rate": 1.0,
  "accuracy": 0.92,
  "avg_confidence": 0.9743899999999996,
  "avg_reason_length": 62.64,
  "corr_confidence_correct": 0.019740392190562284,
  "n": 100
}
```

**æ‰€è¦‹**ï¼š`corr_confidence_correct â‰ˆ 0` ã§ï¼Œ**è‡ªå·±ç”³å‘ŠconfidenceãŒæ­£èª¤ã¨ã»ã¼ç„¡ç›¸é–¢**ã«ãªã‚ŠãŒã¡ï¼
â†’ æœ¬ç¨¿ã®é‹ç”¨ã®é€šã‚Šï¼Œ**â€œæŠ•ç¥¨ç‡â€ã‚’confidenceã«æ¡ç”¨**ã™ã‚‹ã¨æ„å‘³ã®ã‚ã‚‹ä¿¡é ¼åº¦ã«ãªã‚‹ï¼


## ãƒ‘ãƒ¼ã‚¹æˆ¦ç•¥ï¼ˆå‰å›ã¨åŒæ§˜ï¼‰

* å¿œç­”ã‹ã‚‰**æœ€åˆã® `{ ... }`** ã‚’æŠ½å‡ºã—ã¦JSONã¨ã—ã¦èª­ã‚€ï¼ˆ`parser.py`ï¼‰
* `label` ã¯**è¡¨è¨˜ã‚†ã‚Œè£œæ­£**ï¼ˆpos/neg/neu â†’ æ­£å¼è¡¨è¨˜ï¼‰ï¼Œ`confidence` ã¯ **0â€“1ã«ã‚¯ãƒªãƒƒãƒ—**
* ãƒ‘ãƒ¼ã‚¹ä¸èƒ½ã¯ `label=None` æ‰±ã„ï¼ˆè©•ä¾¡æ™‚ã®æ–¹é‡ã¯ 2ã‚¯ãƒ©ã‚¹strict / neutralãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãªã©ã§æ˜ç¤ºï¼‰


## è©•ä¾¡æŒ‡æ¨™ã¨è¦‹æ–¹

* **Accuracy / Precisionï¼ˆMacroï¼‰/ Recallï¼ˆMacroï¼‰/ F1ï¼ˆMacroï¼‰**
* **Confusion Matrix** ã¨ **èª¤åˆ†é¡ã®å…ˆé ­ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼**ï¼ˆã‚¨ãƒ©ãƒ¼åˆ†æã®èµ·ç‚¹ï¼‰
* ã¾ãšæ³¨è¦–ã™ã‚‹ãƒã‚¤ãƒ³ãƒˆï¼š

  1. `f1_macro` ã®æ°´æº–ï¼ˆã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ¯”è¼ƒï¼‰
  2. **few2 â†’ few5** ã§ã®å®‰å®šæ€§æ”¹å–„ï¼ˆç‰¹ã«å¢ƒç•Œä¾‹ã®å–ã‚Šé•ãˆï¼‰
  3. CoTã®**å‡ºåŠ›å´©å£ŠãŒæŠ‘ãˆã‚‰ã‚Œã¦ã„ã‚‹ã‹**ï¼ˆãƒ‘ãƒ¼ã‚¹æˆåŠŸç‡ï¼‰
  4. **æŠ•ç¥¨ç‡confidence**ã¨æ­£è§£ã®æ•´åˆï¼ˆã—ãã„å€¤é‹ç”¨ã®åŸºç¤ï¼‰


## å…¸å‹çš„ãªå¤±æ•—ã¨å¯¾å‡¦

* **æ€è€ƒæ–‡ã‚„å‰ç½®ããŒæ··ã–ã‚‹** â†’ ã€Œ**JSONã®ã¿**ã€ã€Œ**{ã§å§‹ã‚}ã§çµ‚ãˆã‚‹**ã€ã‚’æ˜è¨˜ï¼
* **ãƒ©ãƒ™ãƒ«è¡¨è¨˜ã‚†ã‚Œ** â†’ æ­£è¦åŒ–ãƒ†ãƒ¼ãƒ–ãƒ«ã§æ•‘æ¸ˆï¼ˆpos/neg/neu ãªã©ï¼‰ï¼
* **reasonãŒé•·æ–‡åŒ–** â†’ èªæ•°ä¸Šé™ï¼ˆâ‰¤12èªãªã©ï¼‰ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå´ã§æ˜ç¤ºï¼
* **confidenceãŒã‚¢ãƒ†ã«ãªã‚‰ãªã„** â†’ è‡ªå·±ç”³å‘Šå€¤ã¯æ¨ã¦ã¦**æŠ•ç¥¨ç‡**or**å¤–éƒ¨è¼ƒæ­£**ã¸ï¼

## å®Ÿé¨“çµæœï¼ˆfew-shot / CoT, IMDB, n=100ï¼‰

ã¾ãšå…¨ä½“ã®ã‚¹ã‚³ã‚¢ãƒœãƒ¼ãƒ‰ã§ã‚ã‚‹ï¼

| Variant       | Accuracy | Precision (macro) | Recall (macro) | F1 (macro) |
|:--------------|---------:|------------------:|---------------:|-----------:|
| Zero-shot     | 0.94     | 0.9343            | 0.9458         | 0.9384     |
| Few-shot (2)  | 0.95     | 0.9447            | 0.9542         | 0.9485     |
| Few-shot (5)  | 0.94     | 0.9343            | 0.9458         | 0.9384     |
| CoT           | 0.92     | 0.9147            | 0.9292         | 0.9184     |


![IMDB: Accuracyã¨F1](https://storage.googleapis.com/zenn-user-upload/68efc5669827-20250818.png "Accuracy/F1 bar chart")
![IMDB: ã‚¯ãƒ©ã‚¹åˆ¥Recall](https://storage.googleapis.com/zenn-user-upload/c82c774f88a5-20250818.png "Recall by class")
![IMDB: Accuracyã¨F1](/images/imdb_variants_accuracy_f1.png "Accuracy/F1 bar chart")
![IMDB: ã‚¯ãƒ©ã‚¹åˆ¥Recall](/images/imdb_variants_recall_by_class.png "Recall by class")

### æ··åŒè¡Œåˆ—ï¼ˆPositive/Negativeï¼‰
`[[TP, FN], [FP, TN]]` ã®é †ã§è¡¨ç¤ºï¼š

- Zero-shot / Few-shot(5)ï¼š`[[55, 5], [1, 39]]`
- Few-shot(2)ã€€ã€€ã€€ ã€€ã€€ï¼š`[[56, 4], [1, 39]]`
- CoTã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ï¼š`[[53, 7], [1, 39]]`

### èª­ã¿å–ã‚Šãƒã‚¤ãƒ³ãƒˆ
- **Few-shot(2)** ãŒæœ€è‰¯ï¼ˆAcc=0.95 / F1=0.9485ï¼‰ï¼ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ¯”ã§ **Positiveå†ç¾ç‡ãŒæ”¹å–„ï¼ˆ0.9167â†’0.9333ï¼‰**ï¼
- **Few-shot(5)** ã¯ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã¨ã»ã¼åŒç­‰ â†’ å°è¦æ¨¡ã‚¿ã‚¹ã‚¯ã§ã¯ **ä¾‹æ•°ã®å¢—é‡ãŒå¿…ãšã—ã‚‚åŠ¹ã‹ãªã„** å¯èƒ½æ€§ï¼
- **CoT** ã¯ **Positiveã®å†ç¾ç‡ãŒä½ä¸‹ï¼ˆ0.8833ï¼‰**ï¼ãŸã ã— **Positiveã®ç²¾åº¦ã¯æœ€é«˜ï¼ˆ0.9815ï¼‰** ã§ï¼Œå³ã—ã‚ã«çµã£ã¦ã„ã‚‹æŒ™å‹•ï¼
- å…¨æ‰‹æ³•ã§ **Negativeå´ã¯å®‰å®šï¼ˆå†ç¾ç‡=0.975ã€FP=1ï¼‰**ï¼ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã®åã‚Šï¼ˆNegativeãŒåˆ¤å®šã—ã‚„ã™ã„ï¼‰ã‚’ç¤ºå”†ï¼
- CoTã®**è‡ªå·±ç”³å‘Šä¿¡é ¼åº¦**ã¨æ­£è§£ã®ç›¸é–¢ã¯ **~0.31**ï¼ã—ãã„å€¤é‹ç”¨ã®ä½™åœ°ã‚ã‚Šï¼



## ä»˜éŒ²ï¼šã‚³ãƒãƒ³ãƒ‰é€Ÿæ”»ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

```bash
# ã‚¼ãƒ­/å°‘æ•°ä¾‹/CoT ã‚’åˆ‡ã‚Šæ›¿ãˆã¦IMDB 100ä»¶è©•ä¾¡
python run_vLLM_imdb_variants.py --model mistralai/Mistral-7B-Instruct-v0.3 --variant zero  --num_samples 100
python run_vLLM_imdb_variants.py --model mistralai/Mistral-7B-Instruct-v0.3 --variant few2  --num_samples 100
python run_vLLM_imdb_variants.py --model mistralai/Mistral-7B-Instruct-v0.3 --variant few5  --num_samples 100
python run_vLLM_imdb_variants.py --model mistralai/Mistral-7B-Instruct-v0.3 --variant cot   --num_samples 100

# CoTå“è³ªã®è¦ç´„ï¼ˆrawäºˆæ¸¬ã¨goldã‚’æ¸¡ã—ã¦é›†è¨ˆï¼‰
python analyze_cot_quality.py \
  --gold runs_imdb_variants/imdb_gold.jsonl \
  --pred runs_imdb_variants/imdb_cot_predictions.jsonl \
  --out report_cot_quality.json
```

## å®Ÿéš›ã«ä½¿ã£ãŸã‚³ãƒ¼ãƒ‰


> **è£œè¶³**
>
> * ä¸‹è¨˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ **å®Ÿéš›ã«ä½¿ç”¨ã—ãŸã‚‚ã®**ã§ã™ï¼
> * `run_vLLM_imdb_variants.py`ã¨`analyze_cot_quality.py` ã¯å‰å›ã® `parser.py` ã¨ `evaluate_zero_shot.py` ã‚’åŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç½®ãå‰æã§ã™ï¼ˆãƒ‘ãƒ¼ã‚¹ã¨è©•ä¾¡ã«åˆ©ç”¨ï¼‰ï¼


### run_vLLM_imdb_variants.pyï¼ˆå®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰

```python
import argparse, os, json, random, subprocess, sys
from textwrap import dedent
from datasets import load_dataset
from vllm import LLM, SamplingParams

# å„ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ã„ã¦5æœ¬ãƒ‘ãƒ¼ã‚¹â†’å¤šæ•°æ±ºãƒ©ãƒ™ãƒ«ã‚’1ã¤ã«
from collections import Counter
from parser import extract_json, normalize_label

# ---- åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè‹±èª2ã‚¯ãƒ©ã‚¹ï¼šæ—¢å­˜ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã¨æ•´åˆï¼‰ ----
def prompt_zero(text:str)->str:
    return dedent(f"""
    You are a strict grader. Classify the movie review sentiment into two classes: positive or negative.

    Rules:
    - Clear satisfaction/recommendation â†’ positive
    - Clear dissatisfaction/complaint/refusal â†’ negative
    Output must be only the following JSON schema (no extra text, no markdown, no code fences):
    {{
      "label": "<positive|negative>",
      "confidence": <0.0_to_1.0>,
      "reason": "<one short sentence>"
    }}

    Review:
    {text}
    """).strip()

def build_fewshot_block(examples):
    # examples: list[{"text":..., "label":...}] label in {"positive","negative"}
    lines = []
    for i,ex in enumerate(examples,1):
        lab = ex["label"]
        reason = "clear praise" if lab=="positive" else "explicit dissatisfaction"
        lines.append(f'[Example {i}]\nReview: "{ex["text"].strip()}"\nOutput: {{"label":"{lab}","confidence":0.9,"reason":"{reason}"}}')
    return "\n\n".join(lines)

def prompt_few(text:str, shots):
    return dedent(f"""
    You are a strict grader. Follow the examples and classify movie review sentiment into positive or negative.

    {build_fewshot_block(shots)}

    Rules:
    - Clear satisfaction/recommendation â†’ positive
    - Clear dissatisfaction/complaint/refusal â†’ negative
    Output must be only the following JSON schema (no extra text, no markdown, no code fences):
    {{
      "label": "<positive|negative>",
      "confidence": <0.0_to_1.0>,
      "reason": "<one short sentence>"
    }}

    Review:
    {text}
    """).strip()

def prompt_cot(text:str)->str:
    from textwrap import dedent
    return dedent(f"""
    You are a strict grader. Think briefly inside your head, but DO NOT output your steps.
    Output ONLY the final JSON with no extra text / no markdown / no code fences.
    If the sentiment is ambiguous, choose "negative".

    Rules:
    - Clear satisfaction/recommendation â†’ positive
    - Clear dissatisfaction/complaint/refusal â†’ negative

    Final JSON schema (reason â‰¤ 12 words):
    {{
      "label": "<positive|negative>",
      "confidence": <0.0_to_1.0>,
      "reason": "<one short sentence (â‰¤12 words)>"
    }}

    Start your output with '{{' and end with '}}'.
    Review:
    {text}
    """).strip()


def set_seed(seed:int):
    random.seed(seed)

def get_balanced_shots(train_ds, k):
    # k=2 or 5: åŠã€…ã§ pos/neg ã‚’å–ã‚‹ï¼ˆç«¯æ•°ã¯poså„ªå…ˆï¼‰
    pos = [r for r in train_ds if r["label"]==1]
    neg = [r for r in train_ds if r["label"]==0]
    random.shuffle(pos); random.shuffle(neg)
    take_pos = (k+1)//2
    take_neg = k - take_pos
    shots_raw = [(pos[i]["text"], "positive") for i in range(take_pos)] + \
                [(neg[i]["text"], "negative") for i in range(take_neg)]
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’çŸ­ã‚ã«æ•´å½¢ï¼ˆé•·ã™ãã‚‹ã‚‚ã®ã¯å…ˆé ­ä¸€æ–‡ãªã©ï¼‰
    clean = []
    for t,l in shots_raw:
        t = " ".join(t.strip().split())
        if len(t)>240: t = t[:240] + "..."
        clean.append({"text": t, "label": l})
    return clean

def main():
    ap=argparse.ArgumentParser()
    ap.add_argument("--model", required=True)
    ap.add_argument("--outdir", default="runs_imdb_A40")
    ap.add_argument("--num_samples", type=int, default=100)
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--max_tokens", type=int, default=128)
    ap.add_argument("--temperature", type=float, default=0.0)
    ap.add_argument("--tensor_parallel_size", type=int, default=1)
    ap.add_argument("--dtype", default="auto")
    ap.add_argument("--variant", choices=["zero","few2","few5","cot"], default="zero")
    args=ap.parse_args()

    os.makedirs(args.outdir, exist_ok=True)
    set_seed(args.seed)

    # ---- GOLD ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ï¼ˆå­˜åœ¨ã™ã‚Œã°åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã§å®Ÿè¡Œï¼‰----
    gold_path = os.path.join(args.outdir, "imdb100_gold.jsonl")
    texts = None

    def read_jsonl(path):
        arr=[]
        with open(path, encoding="utf-8") as f:
            for line in f:
                line=line.strip()
                if line:
                    arr.append(json.loads(line))
        return arr

    if os.path.exists(gold_path):
        gold = read_jsonl(gold_path)
        texts = [g["text"] for g in gold]
        if len(texts) != args.num_samples:
            # ä»¶æ•°ãŒé•ã†å ´åˆã¯å…ˆé ­ã‹ã‚‰åˆã‚ã›ã‚‹ï¼ˆå¿…è¦ãªã‚‰ã“ã“ã§ assert ã«ã—ã¦ã‚‚OKï¼‰
            texts = texts[:args.num_samples]
        print("Using existing GOLD:", gold_path, f"(n={len(texts)})")
    else:
        # GOLD ãŒç„¡ã‘ã‚Œã°ä»Šå›ã®ã‚µãƒ³ãƒ—ãƒ«ã§ä½œæˆ
        ds = load_dataset("stanfordnlp/imdb")
        test = ds["test"]
        idx = list(range(len(test)))
        random.shuffle(idx); idx = idx[:args.num_samples]
        subset = test.select(idx)
        def label_to_str(x:int)->str: return "positive" if x==1 else "negative"
        with open(gold_path, "w", encoding="utf-8") as f:
            for r in subset:
                f.write(json.dumps({"text": r["text"], "label": label_to_str(r["label"])}, ensure_ascii=False) + "\n")
        texts = [r["text"] for r in subset]
        print("Saved GOLD:", gold_path, f"(n={len(texts)})")

    # 2) Few-shot ä¾‹ï¼ˆå¿…è¦æ™‚ï¼‰
    shots = None
    if args.variant in {"few2","few5"}:
        # GOLD ã®æœ‰ç„¡ã«é–¢ä¿‚ãªãã€few-shot ç”¨ã« train ã ã‘ãƒ­ãƒ¼ãƒ‰
        ds = load_dataset("stanfordnlp/imdb")
        train = ds["train"]
        k = 2 if args.variant == "few2" else 5
        shots = get_balanced_shots(train, k)

    # 3) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦ï¼ˆGOLD ç”±æ¥ã® texts ã‚’ä½¿ç”¨ï¼‰
    prompts=[]
    for t in texts:
        t = " ".join(t.strip().split())
        if args.variant=="zero":
            p = prompt_zero(t)
        elif args.variant in {"few2","few5"}:
            p = prompt_few(t, shots)
        else:
            p = prompt_cot(t)
        prompts.append(p)

    # 4) ç”Ÿæˆ
    n = 5 if args.variant == "cot" else 1
    temp = 0.6 if args.variant == "cot" else args.temperature
    sampling = SamplingParams(temperature=temp, max_tokens=args.max_tokens, n=n)
    llm = LLM(model=args.model, tensor_parallel_size=args.tensor_parallel_size, dtype=args.dtype)
    outs = llm.generate(prompts, sampling_params=sampling)
    def trim_reason(r, max_words=12):
        if not r: return ""
        return " ".join(r.strip().split()[:max_words])
    pred_rows = []
    for o in outs:
        labels = []
        reasons = []
        confs = []
        for cand in o.outputs:  # næœ¬
            pj = extract_json(cand.text)
            lab = normalize_label(pj.get("label"))
            if lab:
                labels.append(lab)
                reasons.append(trim_reason(pj.get("reason")))
                confs.append(pj.get("confidence"))
        if labels:
            maj = Counter(labels).most_common(1)[0][0]
            if n == 1:
                # å˜ç™ºç”Ÿæˆï¼ˆzero/fewï¼‰ã¯ãã®ã¾ã¾ä»£è¡¨ã‚’æ¡ç”¨
                idx = labels.index(maj)
                rep_reason = reasons[idx] or ""
                rep_conf = confs[idx] if confs[idx] is not None else 0.9
                final_json = {"label": maj, "confidence": float(rep_conf), "reason": rep_reason}
            else:
                # CoT: è‡ªä¿¡å€¤ã¯å¤šæ•°æ±ºã®æŠ•ç¥¨ç‡ã«ç½®æ›
                vote = labels.count(maj) / len(labels)
                rep_reason = reasons[labels.index(maj)]
                final_json = {"label": maj, "confidence": float(vote), "reason": rep_reason}
        else:
            # å…¨æ»…ã—ãŸã‚‰ä¿å®ˆçš„ã« negative
            final_json = {"label":"negative","confidence":0.55,"reason":"fallback"}
        final_str = json.dumps(final_json, ensure_ascii=False)
        pred_rows.append({"output": final_str})

    # 5) äºˆæ¸¬ä¿å­˜
    pred_path = os.path.join(args.outdir, f"imdb100_pred_{args.variant}.jsonl")
    with open(pred_path,"w",encoding="utf-8") as f:
        for row in pred_rows:
            f.write(json.dumps(row, ensure_ascii=False)+"\n")
    print("Saved pred:", pred_path)

    # 6) è©•ä¾¡ï¼ˆæ—¢å­˜ evaluator ã‚’å‘¼ã³å‡ºã—ã€å…ˆé ­JSONã ã‘æŠ½å‡ºã—ã¦ä¿å­˜ï¼‰
    cmd = [
        sys.executable, "evaluate_zero_shot.py",
        "--gold", gold_path, "--pred", pred_path, "--labels", "2class"
    ]
    run = subprocess.run(cmd, capture_output=True, text=True, check=True)
    s = run.stdout
    obj, end = json.JSONDecoder().raw_decode(s)  # å…ˆé ­JSONã®ã¿
    rep_path = os.path.join(args.outdir, f"report_{args.variant}.json")
    with open(rep_path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)
    print("Saved report:", rep_path)

if __name__=="__main__":
    main()
```



### analyze_cot_quality.pyï¼ˆåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰ï¼‰


```python
import json, argparse, statistics
from parser import extract_json, normalize_label

def load_jsonl(p):
    with open(p, encoding="utf-8") as f:
        for line in f:
            line=line.strip()
            if line:
                yield json.loads(line)

def pearson(x, y):
    n=len(x)
    if n<2: return None
    mx=sum(x)/n; my=sum(y)/n
    num=sum((a-mx)*(b-my) for a,b in zip(x,y))
    den=(sum((a-mx)**2 for a in x)*sum((b-my)**2 for b in y))**0.5
    return num/den if den else None

def main():
    ap=argparse.ArgumentParser()
    ap.add_argument("--gold", required=True)
    ap.add_argument("--pred", required=True)  # imdb100_pred_cot.jsonl ã‚’æƒ³å®š
    ap.add_argument("--out", required=True)
    args=ap.parse_args()

    gold=list(load_jsonl(args.gold))
    pred=list(load_jsonl(args.pred))
    assert len(gold)==len(pred), "length mismatch"
    parses=[]; rights=[]; confs=[]; reason_lens=[]

    for g,p in zip(gold,pred):
        raw = p.get("output","")
        parsed = extract_json(raw)
        ok = parsed["label"] is not None
        parses.append(1 if ok else 0)
        y_true = normalize_label(g["label"])
        y_pred = normalize_label(parsed["label"])
        right = (y_true==y_pred) if y_pred is not None else False
        rights.append(1 if right else 0)
        c = parsed["confidence"]
        if c is not None: confs.append(float(c))
        rn = parsed["reason"]
        if rn is not None: reason_lens.append(len(rn.strip()))

    report = {
        "parse_success_rate": sum(parses)/len(parses),
        "accuracy": sum(rights)/len(rights),
        "avg_confidence": (sum(confs)/len(confs)) if confs else None,
        "avg_reason_length": (sum(reason_lens)/len(reason_lens)) if reason_lens else None,
        "corr_confidence_correct": pearson(confs, rights) if confs else None,
        "n": len(gold),
    }
    with open(args.out, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    print("Saved:", args.out)

if __name__=="__main__":
    main()
```



## ãŠã‚ã‚Šã«

ä»Šå›ã®å®Ÿè£…ã‚’é€šã—ã¦ï¼Œã§ããŸã“ã¨ã‚„ã‚ã‹ã£ãŸã“ã¨ï¼Œä»Šå¾Œã®äºˆå®šã‚’ã¾ã¨ã‚ã‚‹ï¼
* **Few-shot**ã§åˆ¤æ–­åŸºæº–ã‚’å…±æœ‰ â†’ **ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã‚ˆã‚Šãƒ–ãƒ¬ãŒæ¸›ã‚‹**ï¼
* **CoT**ã¯**æ€è€ƒ**ã‚’ä¿ƒã™ãŒã€**â€œæœ€çµ‚ã¯JSONã®ã¿â€**ã®çµ±åˆ¶ã¨**å¤šæ•°æ±ºï¼‹æŠ•ç¥¨ç‡confidence**ã§**è©•ä¾¡å¯èƒ½æ€§ã‚’æ‹…ä¿**ã™ã‚‹ã®ãŒå®Ÿå‹™çš„ï¼
* åŒä¸€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸Šã§ **zero / few / cot** ã‚’æ¨ªä¸¦ã³æ¯”è¼ƒã§ãã‚‹ã®ã§ï¼Œ**ãƒ¢ãƒ‡ãƒ«å·®**ã‚„**ä¾‹æ•°ã®åŠ¹æœ**ã‚‚ä¸€è²«ã—ã¦è©•ä¾¡ã§ãã‚‹ï¼


å‰å›ã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®å®Ÿé¨“çµæœã¯95%ç¨‹ã§ã‚ã£ãŸãŸã‚ï¼Œä»Šå›ã®few-shotã¨CoTã®é¢ç™½ã•ã‚„æŠ€è¡“çš„ã«ã™ã”ã„ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‹ã‚Šã¥ã‚‰ã‹ã£ãŸï¼ä»¥ä¸‹ã®ç†ç”±ã«ã‚ˆã‚Šãã®ç‰¹å¾´ã‚’æ´»ã‹ã—ãã‚Œãªã‹ã£ãŸã¨è€ƒãˆã‚‰ã‚Œã‚‹ï¼
- å¤©äº•åŠ¹æœï¼šIMDB 2å€¤ã¯æŒ‡ç¤ºèª¿æ•´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®å¾—æ„é ˜åŸŸï¼ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§æ—¢ã« 95% ä»˜è¿‘ï¼
- ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ï¼ˆn=100ï¼‰ï¼š3ä»¶å·®ï¼3%ã¯çµ±è¨ˆãƒã‚¤ã‚ºç´šï¼ˆä¸Šã®ä¿¡é ¼åŒºé–“å‚ç…§ï¼‰ï¼
- èª²é¡Œç‰¹æ€§ï¼šCoTãŒåŠ¹ãã‚„ã™ã„ã®ã¯æ¨è«–é–ãŒå¿…è¦ãªå•é¡Œï¼ˆè¤‡åˆæ¡ä»¶ãƒ»æ•°ç†ãƒ»é•·æ–‡ç…§åˆãªã©ï¼‰ï¼å˜ç´”2å€¤æ„Ÿæƒ…ã¯**è€ƒãˆã‚‹ã»ã©è‰¯ããªã‚‹ã¨ã¯é™ã‚‰ãªã„**ï¼

ã¾ãŸï¼Œfew-shotã‚„CoTã®å¼·ã¿ãŒç›®ã«è¦‹ãˆã¦ã‚ã‹ã‚‹ã‚ˆã†ã«ãªã‚‹ãŸã‚ã«ã¯ï¼Œä»¥ä¸‹ã®æ§˜ãªå·¥å¤«ãŒå¿…è¦ãã†ã§ã‚ã‚‹ï¼
- ãƒ‰ãƒ¡ã‚¤ãƒ³ç§»è¡Œï¼šIMDBâ†’Amazon/Steam/Twitterï¼ˆæ—¥æœ¬èªï¼‰ãªã©èªå½™ãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼ãŒé•ã†é ˜åŸŸï¼Few-shotã®ä¾‹ç¤ºåŠ¹æœãŒå‡ºã‚„ã™ã„ï¼
- å¤šã‚¯ãƒ©ã‚¹åŒ–ï¼šneutral ã‚’å«ã‚€3å€¤ã¯ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§è½ã¡ã‚„ã™ã„â†’Few-shotã®å¢ƒç•Œæç¤ºãŒåŠ¹ãï¼
- å®Ÿé‹ç”¨è€æ€§ãƒ†ã‚¹ãƒˆï¼šå…¥åŠ›ã«ãƒã‚¤ã‚ºï¼ˆä¸è¦ãƒ˜ãƒƒãƒ€/çµµæ–‡å­—/URL/å¼•ç”¨ç¬¦ï¼‰ã‚’æ··ãœï¼Œãƒ‘ãƒ¼ã‚¹æˆåŠŸç‡ã¨ç²¾åº¦ã®åŠ£åŒ–è€æ€§ã‚’æ¯”è¼ƒï¼