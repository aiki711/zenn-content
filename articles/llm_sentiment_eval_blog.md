---
title: "LLMã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ„Ÿæƒ…æ¨å®šã®å®Ÿé¨“ã‚’ã—ã¦ã¿ã‚‹"
emoji: "ğŸ”"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["AI","LLM","NLP","Sentiment","Evaluation"]
published: true
---

# LLMã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ„Ÿæƒ…æ¨å®šã®å®Ÿé¨“ã‚’ã—ã¦ã¿ã‚‹  
**â€” ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â†’ JSON â†’ å¿œç­”è§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«(ãƒ‘ãƒ¼ã‚¹) â†’ è©•ä¾¡ã¾ã§ã®å†ç¾å¯èƒ½ãªæœ€å°æ§‹æˆ â€”**

*æ›´æ–°: 2025-08-17 04:44*

## TL;DR
- LLMã«**JSONã‚¹ã‚­ãƒ¼ãƒã§å‡ºåŠ›ã‚’å¼·åˆ¶** â†’ ãƒ‘ãƒ¼ã‚¹ã§æ©Ÿæ¢°çš„ã«æŠ½å‡º â†’ æŒ‡æ¨™ã¨æ··åŒè¡Œåˆ—ã§è©•ä¾¡  
- ãƒ‡ãƒ¼ã‚¿ã¯å°è¦æ¨¡ãƒ‡ãƒ–ã‚»ãƒƒãƒˆï¼ˆ3ã‚¯ãƒ©ã‚¹ï¼‰ã¨ IMDBï¼ˆ2ã‚¯ãƒ©ã‚¹ï¼‰ã‚’ä½¿ç”¨
- è©•ä¾¡ã¯ **Accuracy / Precision / Recall / F1ï¼ˆMacroï¼‰/ Confusion Matrix** ã‚’ä¸€ç™ºè¨ˆç®—
- ä»˜éŒ²ã¨ã—ã¦ **Few-shot / CoT** ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚‚ç”¨æ„ã—ã€æ¯”è¼ƒå®Ÿé¨“ãŒã™ãå§‹ã‚ã‚‰ã‚Œã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬è¨­è¨ˆ



## èƒŒæ™¯ã¨ç›®çš„
ã€€æœ¬ç¨¿ã®å®Ÿé¨“ã¯ï¼Œæœ€åˆã¯ã€Œå˜ç´”ã«é¢ç™½ãã†ã ã‹ã‚‰ã€ã¨ã„ã†å¥½å¥‡å¿ƒã‹ã‚‰å§‹ã‚ãŸï¼ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§æ„Ÿæƒ…ã‚’ã©ã‚Œãã‚‰ã„æ­£ã—ãå½“ã¦ã‚‰ã‚Œã‚‹ã®ã‹ã‚’ï¼Œè‡ªåˆ†ã®æ‰‹ã§ç¢ºã‹ã‚ãŸã‹ã£ãŸã‹ã‚‰ã ï¼
ã‚‚ã†ä¸€ã¤ã®å‹•æ©Ÿã¯ï¼Œä»Šå¾Œé€²ã‚ã‚‹ç›¸äº’ç†è§£æ”¯æ´ã®ç ”ç©¶ã«å‘ã‘ã¦ï¼Œãƒ¢ãƒ‡ãƒ«ã‚„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥ã‚Œæ›¿ãˆãªãŒã‚‰å£Šã‚Œãšã«å›ã‚‹è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã—ã¦ãŠãã“ã¨ã§ã‚ã‚‹ï¼
ãã“ã§ï¼Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’JSONå‡ºåŠ›ã§å›ºå®šâ†’ãƒ‘ãƒ¼ã‚¹ã§å½¢å¼æºã‚Œã‚’æ•‘æ¸ˆâ†’åŸºæœ¬æŒ‡æ¨™ã§ã‚µã‚¯ãƒƒã¨è©•ä¾¡ï¼Œã¨ã„ã†æœ€å°æ§‹æˆã‚’ç”¨æ„ã—ãŸï¼
ã“ã‚Œã«ã‚ˆã£ã¦ï¼Œãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å·®ã—æ›¿ãˆã‚‹ã ã‘ã§æ¯”è¼ƒã§ãã‚‹ï¼ä»Šå¾Œã®æ”¹è‰¯ï¼ˆFew-shot/CoT/ãƒ¢ãƒ‡ãƒ«æ¨ªæ–­ï¼‰ã«ã¤ãªãŒã‚‹å®Ÿé¨“ã®è¶³å ´ã‚’ä½œã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ï¼



## ä½¿ã£ãŸã‚³ãƒ¼ãƒ‰ï¼ˆã–ã£ãã‚Šï¼‰
```
prompts.py               # Zero-shot / Few-shot / CoT ã®æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
parser.py                # LLMå¿œç­”ã‹ã‚‰æœ€åˆã®JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºãƒ»æ­£è¦åŒ–
evaluate_zero_shot.py    # æŒ‡æ¨™ï¼ˆAccuracy/Precision/Recall/F1ï¼‰ã¨æ··åŒè¡Œåˆ—ã‚’è¨ˆç®—
labels.json              # ãƒ©ãƒ™ãƒ«é›†åˆï¼ˆ2/3/8ã‚¯ãƒ©ã‚¹ï¼‰
run_vLLM_imdb_zero_shot.py  # vLLMã§IMDB 100ä»¶ã‚’ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆ2ã‚¯ãƒ©ã‚¹è©•ä¾¡
README.md                # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®README
```



## å®Ÿé¨“è¨­è¨ˆ

### ã‚¿ã‚¹ã‚¯
- **3ã‚¯ãƒ©ã‚¹**ï¼špositive / neutral / negative  
- **2ã‚¯ãƒ©ã‚¹**ï¼špositive / negativeï¼ˆIMDBã«åˆã‚ã›ãŸè¨­å®šï¼‰

### å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒï¼ˆLLMã®å›ç­”ã¯**å¿…ãš**ã“ã‚Œã ã‘ï¼‰
```json
{{
  "label": "positive|neutral|negative",
  "confidence": 0.0_to_1.0,
  "reason": "çŸ­ã„æ ¹æ‹ æ–‡"
}}
```

### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã®ãƒã‚¤ãƒ³ãƒˆ
- **ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã®å®šç¾©**ã‚’å†’é ­ã§å›ºå®šï¼ˆæ›–æ˜§ãƒ»äº‹å®Ÿã®ã¿ã¯ neutralï¼‰  
- **JSONå¼·åˆ¶**ã§è©•ä¾¡ã‚’é ‘å¥åŒ–  
- **Fewâ€‘shot**ã¯2ä¾‹ã€**CoT**ã¯æ€è€ƒâ†’æœ€çµ‚JSONã®ã¿å‡ºåŠ›ã®æµã‚Œã‚’æ˜ç¤º  
ï¼ˆå¾Œè¿°ã®ãƒ†ãƒ³ãƒ—ãƒ¬ã‚’ãã®ã¾ã¾ä½¿ãˆã‚‹ï¼Œã¯ãšï¼‰



## å†ç¾æ‰‹é †ï¼ˆ3ã‚¯ãƒ©ã‚¹ï¼šå°è¦æ¨¡ãƒ‡ãƒ–ã‚»ãƒƒãƒˆï¼‰

> æ‰‹å‹•10ä»¶ã§æµã‚Œç¢ºèª â†’ 100ä»¶ã«æ‹¡å¼µã€ã®é †ãŒãŠã™ã™ã‚

1) **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé©ç”¨**ï¼ˆZeroâ€‘shotã®ä¾‹ï¼‰  
```python
from prompts import zero_shot_prompt
p = zero_shot_prompt("ã“ã‚Œã¯æœ€é«˜ï¼ã¾ãŸè²·ã„ã¾ã™ã€‚")
print(p)  # LLMã«ä¸ãˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
```

2) **LLMã¸æŠ•ã’ã‚‹** â†’ è¿”ã£ã¦ããŸJSONã‚’ `predictions.jsonl` ã«1è¡Œ1ä»¶ã§è¿½è¨˜  
ï¼ˆä¾‹ï¼‰
```jsonl
{"output": "{{\"label\":\"positive\",\"confidence\":0.94,\"reason\":\"å¼·ã„æº€è¶³ã®è¡¨ç¾\"}}"}
```

3) **è©•ä¾¡**  
```bash
python evaluate_zero_shot.py --gold sample_dev.jsonl --pred predictions.jsonl --labels 3class
```

å‡ºåŠ›ã¯ Accuracy / Precision / Recall / F1ï¼ˆMacroï¼‰ã¨æ··åŒè¡Œåˆ—ï¼
ã‚¨ãƒ©ãƒ¼ä¾‹ã®å…ˆé ­20ä»¶ã‚‚è‡ªå‹•ã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ï¼



## å†ç¾æ‰‹é †ï¼ˆ2ã‚¯ãƒ©ã‚¹ï¼šIMDB + vLLMï¼‰

1) **IMDBã‹ã‚‰100ä»¶ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° & æ¨è«–å®Ÿè¡Œ**  
```bash
python run_vLLM_imdb_zero_shot.py   --model mistralai/Mistral-7B-Instruct-v0.3   --num_samples 100 --max_tokens 128 --temperature 0.0
```
- `runs_imdb_zero_shot/imdb100_predictions.jsonl` ã¨ `imdb100_gold.jsonl` ãŒä¿å­˜ï¼

2) **è©•ä¾¡**  
```bash
python evaluate_zero_shot.py --gold runs_imdb_zero_shot/imdb100_gold.jsonl                              --pred runs_imdb_zero_shot/imdb100_predictions.jsonl                              --labels 2class
```



## ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å®Ÿä½“ï¼ˆæŠœç²‹ï¼‰

### Zeroâ€‘shotï¼ˆ3ã‚¯ãƒ©ã‚¹ï¼æ—¥æœ¬èªï¼‰
```text
positive / neutral / negative ã®3ã‚¯ãƒ©ã‚¹ã§åˆ¤å®šã€‚
- äº‹å®Ÿã®ã¿ãƒ»æ›–æ˜§ã¯ neutral
- æ˜ç¢ºãªå¥½æ„ã¯ positive
- æ˜ç¢ºãªä¸æº€ã¯ negative
- æŒ‡å®šã® JSON ã‚¹ã‚­ãƒ¼ãƒã§å‡ºåŠ›
```
â€» Fewâ€‘shotï¼ˆä¾‹ç¤º2ä»¶ä»˜ãï¼‰ã¨ CoTï¼ˆæ€è€ƒâ†’æœ€çµ‚JSONã®ã¿å‡ºåŠ›ï¼‰ã‚‚ç”¨æ„ï¼



## ãƒ‘ãƒ¼ã‚¹æˆ¦ç•¥ï¼ˆå£Šã‚Œãªã„ä»•çµ„ã¿ï¼‰
- å¿œç­”æœ¬æ–‡ã‹ã‚‰ **æœ€åˆã® `{ ... }` ã‚’æŠ½å‡ºã—ã¦ JSON ã¨ã—ã¦èª­ã‚€**  
- `label` ã¯ **è¡¨è¨˜ã‚†ã‚Œè£œæ­£**ï¼ˆpos/neg/neu â†’ æ­£å¼è¡¨è¨˜ï¼‰  
- `confidence` ã¯ 0.0â€“1.0 ã«ã‚¯ãƒªãƒƒãƒ—  
- ã©ã†ã—ã¦ã‚‚ãƒ‘ãƒ¼ã‚¹ã§ããªã„å ´åˆã¯ **`label=None` â†’ è©•ä¾¡æ™‚ã¯ neutral ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**

> ã“ã‚Œã§ã€Œä½™è¨ˆãªå‰ç½®ãã‚„èª¬æ˜ãŒæ··ã–ã£ã¦ã‚‚ã€è©•ä¾¡ãŒæ­¢ã¾ã‚‰ãšã«é€²ã‚€ï¼



## è©•ä¾¡æŒ‡æ¨™ã¨å‡ºåŠ›ä¾‹
- **Accuracy / Precisionï¼ˆMacroï¼‰/ Recallï¼ˆMacroï¼‰/ F1ï¼ˆMacroï¼‰**  
- **per-classè©³ç´°** ã¨ **Confusion Matrix** ã‚’JSONã§å‡ºåŠ›  
- ç›´å¾Œã« **èª¤åˆ†é¡ã®å…ˆé ­20ä»¶** ã‚’ãƒ€ãƒ³ãƒ—ã™ã‚‹ã®ã§ã€ã‚¨ãƒ©ãƒ¼åˆ†æãŒå§‹ã‚ã‚„ã™ã„ï¼

å®Ÿé‹ç”¨ã§ã¯æ¬¡ã®3ç‚¹ã‚’ã¾ãšè¦‹ã‚‹ï¼š  
1) `f1_macro` ã®æ°´æº–ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒï¼‰  
2) ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«å‘¨ã‚Šã®å–ã‚Šé•ãˆï¼ˆ`neutralâ†’positive/negative` ã®èª¤ã‚Šï¼‰  
3) ç‰¹å®šãƒ©ãƒ™ãƒ«ã®**ç²¾åº¦ã¨å†ç¾ç‡ã®ã‚¢ãƒ³ãƒãƒ©ãƒ³ã‚¹**ï¼ˆéæ¤œå‡º/éå°‘æ¤œå‡ºï¼‰



## å…¸å‹çš„ãªå¤±æ•—ã¨å¯¾å‡¦
- **LLMãŒJSONä»¥å¤–ã‚‚è¿”ã™** â†’ ãƒ‘ãƒ¼ã‚¹ã§æœ€åˆã®JSONã ã‘æ‹¾ã†ï¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã« **ã€ŒJSONã®ã¿ã€** ã‚’æ˜è¨˜
- **`label`æ¬ è½ã‚„è¡¨è¨˜æºã‚Œ** â†’ æ­£è¦åŒ–ãƒ†ãƒ¼ãƒ–ãƒ«ã§è£œæ­£ï¼ˆpos/neg/neuï¼‰
- **ã©ã†ã—ã¦ã‚‚èª­ã‚ãªã„** â†’ `neutral` ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¦å…ˆã¸é€²ã‚€ï¼ˆå¾Œã§èª¤åˆ†é¡ã¨ã—ã¦ç¢ºèªï¼‰  
- **CoTã§å‡ºåŠ›å´©å£Š** â†’ ã€Œæœ€å¾Œã¯**JSONã®ã¿**ã€ã‚’å¼·èª¿ã€‚`max_tokens` ã‚’ä½™è£•ã‚ã‚‹å€¤ã«



## å®Ÿé¨“çµæœ
```
# (ä¾‹)
"accuracy": 0.96,
Â  "precision_macro": 0.9556650246305418,
Â  "recall_macro": 0.9624999999999999,
Â  "f1_macro": 0.9586606035551881,
Â  "per_class": {
Â  Â  "positive": {
Â  Â  Â  "precision": 0.9827586206896551,
Â  Â  Â  "recall": 0.95,
Â  Â  Â  "f1": 0.9661016949152542
Â  Â  },
Â  Â  "negative": {
Â  Â  Â  "precision": 0.9285714285714286,
Â  Â  Â  "recall": 0.975,
Â  Â  Â  "f1": 0.951219512195122
Â  Â  }
Â  }
```

- æœ¬å®Ÿé¨“ã§ã¯ Accuracy=0.96ã€F1(macro)=0.959 ã¨é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸï¼
- ã‚¯ãƒ©ã‚¹åˆ¥ã«ã¯ positive ã§ Precision=0.983/Recall=0.95ã€negative ã§ Precision=0.929/Recall=0.975 ã¨ãªã‚Šï¼Œ**ãƒã‚¬ãƒ†ã‚£ãƒ–ã®è¦‹è½ã¨ã—ï¼ˆFNï¼‰ã¯å°‘ãªã„ä¸€æ–¹ï¼Œãƒã‚¬éæ¤œå‡ºï¼ˆFPï¼‰ãŒç›¸å¯¾çš„ã«å¤šã„**å‚¾å‘ãŒç¢ºèªã§ããŸï¼ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«ãŒ**ãƒã‚¬åˆ¤å®šã«ã‚„ã‚„æ”»ã‚**ã§ï¼Œ**ãƒã‚¸åˆ¤å®šã‚’æ…é‡**ã«è¡Œã†æ–¹é‡ã‚’æš—ã«å–ã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ï¼èª¤ã‚Šã¯ä¸»ã«**ãƒã‚¸â†’ãƒã‚¬**ã®å–ã‚Šé•ãˆã«ç”±æ¥ã™ã‚‹ã¨æ¨æ¸¬ã•ã‚Œã‚‹ï¼å¯¾ç­–ã¨ã—ã¦ï¼Œ 
  (i) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã§ãƒã‚¬åˆ¤å®šã®åŸºæº–ã‚’ã‚ˆã‚Šå³æ ¼ã«è¦å®šã™ã‚‹
  (ii) è¿”å´ã•ã‚Œã‚‹ä¿¡é ¼åº¦ã«åŸºã¥ããƒã‚¬æ¡ç”¨ã®**ã—ãã„å€¤**ã‚’è¨­ã‘ã‚‹
  (iii) å¢ƒç•Œäº‹ä¾‹ã‚’å«ã‚€**å¯¾ç§°çš„ãªFew-shot**ã‚’ä»˜ä¸ã™ã‚‹
  ã®3ç‚¹ã‚’ææ¡ˆã™ã‚‹ï¼
- åŠ ãˆã¦ï¼Œè©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«ãŒ100ä»¶è¦æ¨¡ã®å ´åˆï¼ŒAccuracy ã®95%CIã¯æ¦‚ã­ [0.90, 0.98] ã§ã‚ã‚Šï¼Œ**Â±4%ç¨‹åº¦ã®çµ±è¨ˆçš„ã‚†ã‚‰ã**ãŒå­˜åœ¨ã™ã‚‹ç‚¹ã«ã‚‚ç•™æ„ãŒå¿…è¦ã§ã‚ã‚‹ï¼
- ä»Šå¾Œã¯ã“ã‚Œã‚‰ã®æ”¹å–„ã‚’åŠ å‘³ã—ï¼ŒFew-shot/CoT/ãƒ¢ãƒ‡ãƒ«å·®ã®æ¨ªæŒã¡æ¯”è¼ƒã‚’è¡Œã„ï¼Œç‰¹ã« negative ã® Precision æ”¹å–„ã¨å†ç¾æ€§ã®ç¢ºèªã‚’é€²ã‚ã‚‹ï¼


## ç•™æ„äº‹é …
æœ¬ç¨¿ã¯2ã‚¯ãƒ©ã‚¹ï¼ˆpositive/negativeï¼‰è©•ä¾¡ã§ã‚ã‚‹ãŒï¼Œãƒ‘ãƒ¼ã‚¹ã¯å°†æ¥ã®æ‹¡å¼µã‚’è¦‹æ®ãˆãŸ3ã‚¯ãƒ©ã‚¹å¯¾å¿œã®æ±ç”¨è¨­è¨ˆã¨ãªã£ã¦ã„ã‚‹ï¼æ¨è«–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯2ã‚¯ãƒ©ã‚¹ã®ã¿ã‚’è¨±ã™JSONã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ã£ã¦ã„ã‚‹ãŸã‚ï¼Œé€šå¸¸ã¯ neutral ã¯å‡ºåŠ›ã•ã‚Œãªã„ï¼ãªãŠï¼Œ2ã‚¯ãƒ©ã‚¹å¤–ï¼ˆãƒ‘ãƒ¼ã‚¹ä¸èƒ½/neutralï¼‰ãŒå‡ºãŸå ´åˆã«ã©ã†æ‰±ã†ã‹ã§æŒ‡æ¨™ãŒå¤‰ã‚ã‚‹ã®ã§ï¼Œstrictãƒ¢ãƒ¼ãƒ‰ï¼ˆ2ã‚¯ãƒ©ã‚¹å¤–ã‚’èª¤ã‚Šã¨ã—ã¦é›†è¨ˆï¼‰ã¾ãŸã¯ invalidã‚¯ãƒ©ã‚¹ã®æ˜ç¤ºåŒ–ã‚’æ¨å¥¨ã™ã‚‹ï¼



## ç™ºå±•ï¼ˆFewâ€‘shot / CoT / LoRAï¼‰
- å°‘æ•°ä¾‹ã‚’å…¥ã‚Œã‚‹ã¨ `reason` ã®è³ªãŒä¸ŠãŒã‚Šã€ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã®æ‰±ã„ãŒå®‰å®šåŒ–ã™ã‚‹ã“ã¨ãŒå¤šã„ 
- CoTã¯ç†ç”±æ–‡ãŒè‰¯ããªã‚‹ä¸€æ–¹ã§**å‡ºåŠ›å´©å£Šãƒªã‚¹ã‚¯**ãŒã‚ã‚‹ãŸã‚ã€**æœ€å¾Œã«JSONã®ã¿**ã‚’å†åº¦å¼·åˆ¶
- LoRAå¾®èª¿æ•´ã‚’æ¤œè¨ã™ã‚‹å ´åˆã‚‚ã€æœ¬è¨˜äº‹ã®**åŒã˜è©•ä¾¡é–¢æ•°**ã‚’æµç”¨ã™ã‚Œã°æ¯”è¼ƒãŒå…¬æ­£ã«ãªã‚‹



## ä»˜éŒ²ï¼šã‚³ãƒãƒ³ãƒ‰é€Ÿæ”»ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹
```bash
# 3ã‚¯ãƒ©ã‚¹ï¼ˆä»»æ„ã®LLM â†’ å¿œç­”ã‚’predictions.jsonlã«æ ¼ç´ï¼‰
python evaluate_zero_shot.py --gold sample_dev.jsonl --pred predictions.jsonl --labels 3class

# 2ã‚¯ãƒ©ã‚¹ï¼ˆIMDB x vLLMï¼‰
python run_vLLM_imdb_zero_shot.py --model mistralai/Mistral-7B-Instruct-v0.3
python evaluate_zero_shot.py --gold runs_imdb_zero_shot/imdb100_gold.jsonl                              --pred runs_imdb_zero_shot/imdb100_predictions.jsonl                              --labels 2class
```




## å®Ÿéš›ã«ä½¿ã£ãŸã‚³ãƒ¼ãƒ‰

> ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ³¨æ„ï¼šå…¬é–‹æ™‚ã¯ APIã‚­ãƒ¼ã‚„å€‹äººæƒ…å ±ã€ç¤¾å†…URLãªã©**ç§˜å¯†æƒ…å ±ã‚’å«ã‚ãªã„**ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

### `evaluate_zero_shot.py` â€” è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ2ã‚¯ãƒ©ã‚¹/3ã‚¯ãƒ©ã‚¹å¯¾å¿œï¼‰
- å…¥åŠ›ï¼š`--gold`ï¼ˆæ­£è§£JSONLï¼‰ã€`--pred`ï¼ˆLLMã®å‡ºåŠ›JSONLï¼‰  
- å‡ºåŠ›ï¼šAccuracy / Precision / Recall / F1ï¼ˆmacroï¼‰ã¨æ··åŒè¡Œåˆ—ã€èª¤åˆ†é¡ã®å…ˆé ­20ä»¶ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼

```python:evaluate_zero_shot.py
import json, argparse, collections
from typing import List, Dict
from parser import extract_json, normalize_label

def load_jsonl(path: str) -> List[dict]:
    with open(path, "r", encoding="utf-8") as f:
        return [json.loads(line) for line in f]

def classification_report(y_true: List[str], y_pred: List[str], labels: List[str]) -> Dict:
    # Precision / Recall / F1 (macro) + Confusion
    cm = {l:{ll:0 for ll in labels} for l in labels}
    for t, p in zip(y_true, y_pred):
        if t in labels and p in labels:
            cm[t][p] += 1
    # per-class
    precs, recs, f1s = [], [], []
    for l in labels:
        tp = cm[l][l]
        fp = sum(cm[ll][l] for ll in labels if ll != l)
        fn = sum(cm[l][ll] for ll in labels if ll != l)
        prec = tp / (tp + fp) if (tp+fp) > 0 else 0.0
        rec = tp / (tp + fn) if (tp+fn) > 0 else 0.0
        f1 = 2*prec*rec/(prec+rec) if (prec+rec) > 0 else 0.0
        precs.append(prec); recs.append(rec); f1s.append(f1)
    acc = sum(cm[l][l] for l in labels) / max(1, sum(sum(cm[l].values()) for l in labels))
    report = {
        "accuracy": acc,
        "precision_macro": sum(precs)/len(labels),
        "recall_macro": sum(recs)/len(labels),
        "f1_macro": sum(f1s)/len(labels),
        "per_class": {l: {"precision":p, "recall":r, "f1":f}
                      for l, p, r, f in zip(labels, precs, recs, f1s)},
        "confusion_matrix": cm
    }
    return report

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--gold", required=True, help="Gold JSONL: {text:str, label:str} per line")
    ap.add_argument("--pred", required=True, help="Predictions JSONL: LLM raw outputs per line OR {output:str}")
    ap.add_argument("--labels", default="3class", choices=["2class","3class"])
    args = ap.parse_args()

    labels = ["positive","negative"] if args.labels=="2class" else ["positive","neutral","negative"]
    gold = load_jsonl(args.gold)
    pred_raw = load_jsonl(args.pred)

    if len(gold) != len(pred_raw):
        raise ValueError(f"Length mismatch: gold={len(gold)} vs pred={len(pred_raw)}")

    y_true, y_pred, parsed_rows = [], [], []
    for g, pr in zip(gold, pred_raw):
        gold_label = normalize_label(g.get("label"))
        raw_text = pr.get("output") or pr.get("text") or json.dumps(pr, ensure_ascii=False)
        parsed = extract_json(raw_text)
        pred_label = normalize_label(parsed["label"])
        y_true.append(gold_label)
        # 2ã‚¯ãƒ©ã‚¹é‹ç”¨ã§ã‚‚ã€ãƒ‘ãƒ¼ã‚¹ä¸èƒ½ã¯ 'neutral' ã«è½ã¨ã™ï¼ˆåˆ†æ¯ã‹ã‚‰å¤–ã‚Œã‚‹â†’åˆ¥é›†è¨ˆã§ç¢ºèªï¼‰
        y_pred.append(pred_label if pred_label is not None else "neutral")
        parsed_rows.append({"gold":gold_label, "pred":pred_label, "confidence":parsed["confidence"], "reason":parsed["reason"]})

    report = classification_report(y_true, y_pred, labels)
    print(json.dumps(report, ensure_ascii=False, indent=2))

    # ã‚¨ãƒ©ãƒ¼è§£æç”¨ã®å…ˆé ­20ä»¶ã‚’ãƒ€ãƒ³ãƒ—
    errors = [r for r in parsed_rows if r["gold"] != r["pred"]]
    preview = {"num_errors": len(errors), "preview": errors[:20]}
    print("
# Errors (first 20)
")
    print(json.dumps(preview, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
```

---

### `parser.py` â€” LLMå¿œç­”ã®JSONæŠ½å‡ºã¨æ­£è¦åŒ–
- å¿œç­”æœ¬æ–‡ã‹ã‚‰**æœ€åˆã® `{...}`** ã‚’æ‹¾ã£ã¦JSONã¨ã—ã¦èª­ã‚€  
- `label` ã®è¡¨è¨˜ã‚†ã‚Œï¼ˆpos/neg/neuãªã©ï¼‰ã‚’è£œæ­£ã€`confidence` ã‚’ 0â€“1 ã«ã‚¯ãƒªãƒƒãƒ—

```python:parser.py
import json, re

VALID_3 = {"positive", "neutral", "negative"}

def extract_json(text: str) -> dict:
    """
    å¿œç­”æœ¬æ–‡ã‹ã‚‰æœ€åˆã®JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºã—ã¦parseã™ã‚‹ã€‚
    å¤±æ•—ã—ãŸã‚‰ç©ºã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è¿”ã™ã€‚
    """
    # æœ€åˆã® { ã‹ã‚‰æœ€å¾Œã® } ã¾ã§ã®æœ€çŸ­ä¸€è‡´ã‚’è©¦ã¿ã‚‹
    m = re.search(r'\{.*\}', text, flags=re.S)
    if not m:
        return {"label": None, "confidence": None, "reason": None, "raw": text}
    snippet = m.group(0)
    try:
        data = json.loads(snippet)
    except Exception:
        return {"label": None, "confidence": None, "reason": None, "raw": text}
    # æ­£è¦åŒ–
    label = (data.get("label") or "").strip().lower()
    if label not in VALID_3:
        # ã‚ˆãã‚ã‚‹è¡¨è¨˜ã‚†ã‚Œã‚’è£œæ­£
        alias = {
            "pos": "positive", "positive ": "positive",
            "neg": "negative", "negative ": "negative",
            "neu": "neutral", "neutral ": "neutral"
        }
        label = alias.get(label, None)
    conf = data.get("confidence")
    try:
        conf = float(conf) if conf is not None else None
        if conf is not None:
            conf = max(0.0, min(1.0, conf))
    except Exception:
        conf = None
    reason = data.get("reason")
    return {"label": label, "confidence": conf, "reason": reason, "raw": text}

def normalize_label(x: str) -> str:
    x = (x or "").strip().lower()
    if x in VALID_3: return x
    if x in {"pos"}: return "positive"
    if x in {"neg"}: return "negative"
    if x in {"neu", "neutrality"}: return "neutral"
    return None
```

---

### `prompts.py` â€”ï¼ˆå°†æ¥ã®3ã‚¯ãƒ©ã‚¹æ‹¡å¼µå‘ã‘ãƒ†ãƒ³ãƒ—ãƒ¬ï¼‰
- ä»Šå›ã®ãƒ–ãƒ­ã‚°ã¯2ã‚¯ãƒ©ã‚¹ä¸­å¿ƒã§ã™ãŒã€**3ã‚¯ãƒ©ã‚¹æ‹¡å¼µ**ã‚’è¦‹æ®ãˆãŸãƒ†ãƒ³ãƒ—ãƒ¬ã‚‚ç½®ã„ã¦ãŠãã¾ã™ã€‚

```python:prompts.py
from textwrap import dedent

DEFAULT_SCHEMA = """\
å¿…ãšæ¬¡ã®JSONå½¢å¼ã®ã¿ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
{
  "label": "<positive|neutral|negative ã®ã„ãšã‚Œã‹>",
  "confidence": <0.0ã‹ã‚‰1.0>,
  "reason": "<æ ¹æ‹ ã‚’æ—¥æœ¬èªã§1æ–‡ä»¥å†…>"
}
"""

def zero_shot_prompt(text: str) -> str:
    """3å€¤æ„Ÿæƒ…åˆ†æã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ—¥æœ¬èªï¼‰ã€‚"""
    return dedent(f"""
    ã‚ãªãŸã¯å³å¯†ãªæ¡ç‚¹è€…ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ã€Œç­†è€…ã®è©•ä¾¡çš„æ…‹åº¦ã€ã‚’
    positive / neutral / negative ã®3ã‚¯ãƒ©ã‚¹ã§åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
    
    ãƒ«ãƒ¼ãƒ«:
    - ã€Œäº‹å®Ÿã®ã¿ã®èª¬æ˜ã€ã€Œã©ã¡ã‚‰ã¨ã‚‚å–ã‚Œãªã„æ›–æ˜§ã€ã¯ neutral
    - æ˜ç¢ºãªå¥½æ„ãƒ»æº€è¶³ãƒ»æ¨å¥¨ã¯ positive
    - æ˜ç¢ºãªä¸æº€ãƒ»æ‰¹åˆ¤ãƒ»è½èƒ†ãƒ»æ‹’å¦ã¯ negative
    - å‡ºåŠ›ã¯å¿…ãšæŒ‡å®šã® JSON ã‚¹ã‚­ãƒ¼ãƒã«å¾“ã†ã“ã¨
    
    ãƒ†ã‚­ã‚¹ãƒˆ:
    ```
    {text}
    ```
    
    {DEFAULT_SCHEMA}
    """).strip()

def few_shot_prompt(text: str) -> str:
    """2ä¾‹ã®Few-shotã¤ããƒ†ãƒ³ãƒ—ãƒ¬ã€‚"""
    return dedent(f"""
    ã‚ãªãŸã¯å³å¯†ãªæ¡ç‚¹è€…ã§ã™ã€‚ä»¥ä¸‹ã®ä¾‹ã«å¾“ã„ã€ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®
    sentiment ã‚’ positive / neutral / negative ã®3ã‚¯ãƒ©ã‚¹ã§åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
    
    [ä¾‹1]
    ãƒ†ã‚­ã‚¹ãƒˆ: "æœ€é«˜ã®ä½“é¨“ã§ã—ãŸã€‚ã¾ãŸå¿…ãšè³¼å…¥ã—ã¾ã™ã€‚"
    å‡ºåŠ›: {{"label":"positive","confidence":0.94,"reason":"å¼·ã„æº€è¶³ã¨å†è³¼å…¥æ„æ€"}}
    
    [ä¾‹2]
    ãƒ†ã‚­ã‚¹ãƒˆ: "æ€ã£ãŸã‚ˆã‚Šæ™®é€šã§ã—ãŸã€‚ç‰¹ã«å¯ã‚‚ãªãä¸å¯ã‚‚ãªã—ã€‚"
    å‡ºåŠ›: {{"label":"neutral","confidence":0.82,"reason":"è©•ä¾¡ãŒä¸­ç«‹ã§æ„Ÿæƒ…ãŒå¼±ã„"}}
    
    ãƒ«ãƒ¼ãƒ«:
    - ã€Œäº‹å®Ÿã®ã¿ã®èª¬æ˜ã€ã€Œã©ã¡ã‚‰ã¨ã‚‚å–ã‚Œãªã„æ›–æ˜§ã€ã¯ neutral
    - æ˜ç¢ºãªå¥½æ„ãƒ»æº€è¶³ãƒ»æ¨å¥¨ã¯ positive
    - æ˜ç¢ºãªä¸æº€ãƒ»æ‰¹åˆ¤ãƒ»è½èƒ†ãƒ»æ‹’å¦ã¯ negative
    - å‡ºåŠ›ã¯å¿…ãšJSONã‚¹ã‚­ãƒ¼ãƒã«å¾“ã†
    
    ãƒ†ã‚­ã‚¹ãƒˆ:
    ```
    {text}
    ```
    
    {DEFAULT_SCHEMA}
    """).strip()

def cot_prompt(text: str) -> str:
    """Chain-of-Thoughtã‚’èª˜å°ã—ã¤ã¤ã€æœ€çµ‚çš„ã«JSONã ã‘è¿”ã•ã›ã‚‹æ§‹æˆã€‚"""
    return dedent(f"""
    ã‚ãªãŸã¯å³å¯†ãªæ¡ç‚¹è€…ã§ã™ã€‚ä»¥ä¸‹ã®æ‰‹é †ã§è€ƒãˆã€æœ€å¾Œã« **JSONã®ã¿** ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    æ‰‹é †:
    1) ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è©•ä¾¡çš„è¡¨ç¾ï¼ˆè‚¯å®š/å¦å®š/ä¸­ç«‹ï¼‰ã‚’æŠ½å‡ºï¼ˆæ€è€ƒã¯æ—¥æœ¬èªã§ç°¡æ½”ã«ï¼‰
    2) æœ€çµ‚ãƒ©ãƒ™ãƒ«ã‚’ positive / neutral / negative ã®ã„ãšã‚Œã‹ã§æ±ºå®š
    3) JSONã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦å‡ºåŠ›
    
    ãƒ†ã‚­ã‚¹ãƒˆ:
    ```
    {text}
    ```
    
    {DEFAULT_SCHEMA}
    """).strip()
```

---

### `run_vLLM_imdb_zero_shot.py` â€” vLLMã§IMDBã‚’2ã‚¯ãƒ©ã‚¹è©•ä¾¡
- `--model` ã«Hugging Faceã®ãƒ¢ãƒ‡ãƒ«åã‚’æ¸¡ã™ã ã‘ã€‚äºˆæ¸¬ï¼ˆraw JSONæ–‡å­—åˆ—ï¼‰ã¨æ­£è§£ï¼ˆgoldï¼‰ã‚’ `.jsonl` ã«ä¿å­˜ã—ã¾ã™ã€‚

```python:run_vLLM_imdb_zero_shot.py
"""
run_vLLM_imdb_zero_shot.py

vLLM ã‚’ç”¨ã„ã¦ IMDB ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ 100ä»¶ã§ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆ 2ã‚¯ãƒ©ã‚¹æ„Ÿæƒ…åˆ†æï¼ˆpositive/negativeï¼‰ã‚’å®Ÿè¡Œã€‚
- ãƒ¢ãƒ‡ãƒ«ã¯ Hugging Face Hub åã‚’å¼•æ•°ã§æŒ‡å®šï¼ˆä¾‹: mistralai/Mistral-7B-Instruct-v0.3ï¼‰
- é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ï¼ˆAWQ/GPTQï¼‰ãªã‚‰ VRAM ã‚’å¤§å¹…ã«ç¯€ç´„å¯èƒ½ï¼ˆä¾‹: TheBloke/*-AWQï¼‰
- ç”Ÿæˆå‡ºåŠ›ã¯ JSON å½¢å¼ã‚’å¼·åˆ¶ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚è§£æã¯æ—¢å­˜ `evaluate_zero_shot.py` ã‚’ä½¿ç”¨ã€‚
"""
import argparse, json, random, os
from datasets import load_dataset
from vllm import LLM, SamplingParams
from textwrap import dedent

def set_seed(seed: int):
    random.seed(seed)

def prompt_2class(text: str) -> str:
    return dedent(f"""
    You are a strict grader. Classify the review sentiment into two classes: positive or negative.
    
    Rules:
    - Clear satisfaction/recommendation â†’ positive
    - Clear dissatisfaction/complaint/refusal â†’ negative
    - Output must be only the following JSON schema:
    {{
      "label": "<positive|negative>",
      "confidence": <0.0_to_1.0>,
      "reason": "<one short sentence>"
    }}
    
    Review:
    ```
    {text}
    ```
    """).strip()

def label_to_str(x: int) -> str:
    # IMDB: 0=neg, 1=pos
    return "positive" if x == 1 else "negative"

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--model", required=True, help="HF model id (e.g., mistralai/Mistral-7B-Instruct-v0.3)")
    ap.add_argument("--outdir", default="runs_imdb_zero_shot")
    ap.add_argument("--num_samples", type=int, default=100)
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--max_tokens", type=int, default=128)
    ap.add_argument("--temperature", type=float, default=0.0)
    ap.add_argument("--tensor_parallel_size", type=int, default=1)
    ap.add_argument("--dtype", default="auto", help="auto|half|bfloat16|float32 etc (forwarded to vLLM)")
    args = ap.parse_args()

    os.makedirs(args.outdir, exist_ok=True)
    set_seed(args.seed)

    # 1) load IMDB
    ds = load_dataset("stanfordnlp/imdb")
    test = ds["test"]
    idx = list(range(len(test)))
    random.shuffle(idx)
    idx = idx[:args.num_samples]
    subset = test.select(idx)

    # 2) prepare prompts
    prompts = [prompt_2class(x["text"]) for x in subset]

    # 3) init vLLM
    sampling = SamplingParams(
        temperature=args.temperature,
        max_tokens=args.max_tokens,
        stop=[],  # JSONã®ã¿ã‚’ä¿ƒã™ãŸã‚ stop ã¯ç„¡ã—
    )
    llm = LLM(model=args.model, tensor_parallel_size=args.tensor_parallel_size, dtype=args.dtype)
    
    # 4) generate
    outputs = llm.generate(prompts, sampling_params=sampling)
    # vLLM outputs: list[RequestOutput] -> .outputs[0].text
    texts = [o.outputs[0].text if o.outputs else "" for o in outputs]

    # 5) save predictions (raw), and gold
    pred_path = os.path.join(args.outdir, "imdb100_predictions.jsonl")
    gold_path = os.path.join(args.outdir, "imdb100_gold.jsonl")
    with open(pred_path, "w", encoding="utf-8") as f:
        for t in texts:
            f.write(json.dumps({"output": t}, ensure_ascii=False) + "\n")
    with open(gold_path, "w", encoding="utf-8") as f:
        for row in subset:
            f.write(json.dumps({"text": row["text"], "label": label_to_str(row["label"])}, ensure_ascii=False) + "\n")

    print(f"Saved predictions to: {pred_path}")
    print(f"Saved gold to:        {gold_path}")
    print("\næ¬¡ã®è©•ä¾¡ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š")
    print(f"python evaluate_zero_shot.py --gold {gold_path} --pred {pred_path} --labels 2class")

if __name__ == "__main__":
    main()
```

## ãŠã‚ã‚Šã«
ä»Šå›ã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå®Ÿé¨“ã§ã¯ï¼ŒAccuracy 0.96ï¼F1(macro) 0.959 ã¨ã„ã†è‡ªåˆ†ã®æƒ³å®šã‚’å¤§ããä¸Šå›ã‚‹çµæœãŒå¾—ã‚‰ã‚ŒãŸï¼æ­£ç›´ï¼ŒLLMãŒè¿½åŠ å­¦ç¿’ãªã—ã§ã“ã“ã¾ã§å®‰å®šã—ã¦åˆ¤å®šã§ãã‚‹ã¨ã¯æ€ã£ã¦ãŠã‚‰ãšï¼Œ**ã€Œãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥ã‚Œã¦ã€è¿”ã£ã¦ããŸJSONã‚’è©•ä¾¡ã™ã‚‹ã ã‘ã€** ã¨ã„ã†æ‰‹è»½ã•ã«ã‚‚é©šã‹ã•ã‚ŒãŸï¼æœ€å°æ§‹æˆã§ã‚‚ï¼Œååˆ†ã«**å†ç¾å¯èƒ½ãªè©•ä¾¡**ã«åˆ°é”ã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã§ããŸã®ã¯å¤§ããªåç©«ã§ã‚ã‚‹ï¼

ä¸€æ–¹ã§ï¼Œè©•ä¾¡å¯¾è±¡ã¯IMDBã®2ã‚¯ãƒ©ã‚¹ãƒ»ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚‚é™å®šçš„ã§ã‚ã‚Šï¼Œ**åˆ†å¸ƒã®é•ã„** ã«å¯¾ã™ã‚‹é ‘å¥æ€§ã¯ä»Šå¾Œã®æ¤œè¨¼èª²é¡Œã ï¼ã‚¯ãƒ©ã‚¹åˆ¥ã®èª¤ã‚Šã‚’è¦‹ã‚‹ã¨ï¼Œ**ãƒã‚¬åˆ¤å®šã®åŸºæº–ã‚’å³æ ¼åŒ–**ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿®æ­£ã‚„ï¼Œ**confidenceã—ãã„å€¤**ã®å°å…¥ã§æ”¹å–„ã§ãã‚‹è¦‹è¾¼ã¿ãŒã‚ã‚‹ï¼

æ¬¡ã®ä¸€æ­©ã¨ã—ã¦ï¼Œ
1. Few-shot/Cotã®å°å…¥ã¨å¢ƒç•Œäº‹ä¾‹ã®æç¤ºï¼Œ
2. ãƒ¢ãƒ‡ãƒ«æ¨ªæ–­æ¯”è¼ƒï¼ˆMistral/Llama/Qwen/æ—¥æœ¬èªç‰¹åŒ–ç³»ï¼‰
3. 3ã‚¯ãƒ©ã‚¹è¨­å®šã§ã®ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã®å®‰å®šåŒ–ï¼Œ
4. confidenceã«åŸºã¥ãé‹ç”¨ä¸Šã®ã—ãã„å€¤è¨­è¨ˆï¼ˆRecall/Precisionã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•æœ€é©åŒ–ï¼‰

ã‚’é€²ã‚ãŸã„ï¼

ä»Šå›ã®ã€Œ**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆâ†’JSONâ†’ãƒ‘ãƒ¼ã‚¹â†’è©•ä¾¡**ã€ã¨ã„ã†è¶³å ´ã‚’èµ·ç‚¹ã«ï¼Œãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã¨è¦æ±‚ç²¾åº¦ã«åˆã‚ã›ã¦æ®µéšçš„ã«å¼·åŒ–ã—ã¦ã„ãï¼
