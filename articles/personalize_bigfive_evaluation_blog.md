---
title: "LLMはBig Fiveの人格をどこまで再現するのかに関する論文を一緒に読みましょう！"
emoji: "🕌"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["LLM","Personalization","BigFive","Evaluation"]
published: false
---


# LLMはBig Fiveの“人格”をどこまで再現する？— GPT-4・Llama-2・Mixtralでの実証
> この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと**同じ目線**で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！


# TL;DR
- IPIP-NEO-120（120項目）をLLMに実施し、**GPT-4 / Llama-2 / Mixtral**の**Big Five（外向性・開放性・協調性・誠実性・神経症傾向）**スコアを比較。**モデルごとに異なる“人格的傾向”が出る**ことを追加証拠として報告。小さな**プロンプト差や温度**での安定性も検証。
- 結果（代表所見）：**GPT-4は外向性が高め**、**Llama-2は中庸だが神経症傾向がやや高め**、**Mixtralは神経症傾向が低く、開放性・協調性・誠実性が高め**。温度の影響は限定的で、**プロンプト差は全モデルに効く**。
- **限界**：温度効果は結論が出ず、ケーススタディ規模ゆえ**一般化には注意**。ただし**会話エージェントの個人化設計**への示唆は大きい。



# 背景：なぜLLMの“人格”を見るのか
- ドメインや用途（チュータ、ヘルスケア、NPC等）に応じて、**望ましい言語スタイルは異なる**。Big Five は人間側テキストの安定した性格記述として広く再現性があり、**LLM出力の“人格的性質”を測る軸**として妥当。
- 先行研究は、**プロンプトや微調整**でBig Five 傾向を**誘導可能**であることを示してきた。本研究は**GPT-4 / Llama-2 / Mixtral**の比較と**安定性検証**を追加。



# 実験デザイン
- **質問紙**：**IPIP-NEO-120**（Likert 1–5）。質問文を逐次提示し、**数値のみ回答**させるプロンプトを使用。
- **プロンプト2種**：通常版と「**[Answer as if you were a person.]**」を1行加えた変種（ガードにより応答拒否が出るケースを回避する目的）。
- **モデルと温度**：**GPT-4**（t=1,1.5,2）、**Llama-2/Mixtral**（t=0.3,0.7,1）。各条件**5回反復**し平均±SDを報告。**温度×プロンプト**で計6トリートメント。



# 結果（ハイライト）
- **モデル間差**：  
  - **GPT-4**：**外向性が最も高い**傾向。
  - **Llama-2**：**全体中庸**だが、**神経症傾向が相対的に高め**。
  - **Mixtral**：**神経症傾向が低く**、**開放性・協調性・誠実性が高い**。
- **安定性**：**温度の影響は限定的**（**GPT-4のみ**性格スコアがやや反応）。一方、**プロンプトの小差**（上記1行の有無）は**全モデルに影響**。

> 言い換え：**同じBig Fiveでもモデルごとに“出やすい人格”が違う**＋**プロンプトの設計が地味に効く**。



# 考察：実務での示唆
- **用途適合**：  
  - **社交性/創作性重視**→ GPT-4が向く可能性。  
  - **感情を交えた表現**→ Llama-2の神経症傾向の高さが効く場面も（要ガード）。  
  - **落ち着き・協調性・誠実性重視**→ Mixtral。
- **設計ポイント**：  
  - ベースモデルの**“デフォ人格”差**を踏まえ、**プロンプトや温度の影響を小テストで事前較正**。  
  - **人格誘導（prompting/fine-tuning）**は効くが、**安定性の検証**を同時に回す。



# 限界と注意点
- **温度効果は決定的でない**：本設定では**有意な結論に至らず**。
- **一般化範囲が限定**：**ケーススタディ規模**で、LLMの汎用性ゆえ**他条件への外挿は慎重に**
- **倫理**：人格推定・誘導は**人間同様の人格付与を意図しない**（LLMはエージェンシーを持たない）前提で扱うこと。



# まとめ
- **LLMの“人格的プロファイル”はモデルごとに有意に異なる**。**小さなプロンプト差**でもスコアが動くため、**個人化・会話設計では事前較正が重要**。温度の影響は限定的との示唆だが、**広い条件での一般化検証**が今後の課題。



# 参考（論文情報）

- **タイトル**：*LLMs Simulate Big Five Personality Traits:
Further Evidence*
- **著者**：Aleksandra Sorokovikova, Natalia Fedorova, Sharwin Rezagholi, Ivan P. Yamshchikov
- **年**：2024
- **aclanthology.org**： [リンクはこちら](https://aclanthology.org/2024.personalize-1.7.pdf)