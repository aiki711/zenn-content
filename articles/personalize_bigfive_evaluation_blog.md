---
title: "LLMはBig Fiveの人格をどこまで再現するのかに関する論文を一緒に読みましょう！"
emoji: "🕌"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["LLM","Personalization","BigFive","Evaluation"]
published: True
---


# LLMはBig Fiveの“人格”をどこまで再現する？— GPT-4・Llama-2・Mixtralでの実証
> この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと**同じ目線**で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！


# TL;DR
- IPIP-NEO-120（120項目）をLLMに実施し，**GPT-4 / Llama-2 / Mixtral**の**Big Five（外向性・開放性・協調性・誠実性・神経症傾向）**スコアを比較．**モデルごとに異なる“人格的傾向”が出る**ことを追加証拠として報告．小さな**プロンプト差や温度**での安定性も検証．
- 結果（代表所見）：**GPT-4は外向性が高め**，**Llama-2は中庸だが神経症傾向がやや高め**，**Mixtralは神経症傾向が低く，開放性・協調性・誠実性が高め**．温度の影響は限定的で，**プロンプト差は全モデルに効く**．
- **限界**：温度効果は結論が出ず，ケーススタディ規模ゆえ**一般化には注意**．ただし**会話エージェントの個人化設計**への示唆は大きい．



# 背景：なぜLLMの“人格”を見るのか
- 会話エージェントは用途ごと（チュータ／ヘルスケア／ゲームNPCなど）に望まれる言語スタイルが異なる．そこで，LLMの出力が人間の性格特性（Big Five）に対応する性質をどの程度示すのかを把握し，個人化やHCI設計に生かす．
- ドメインや用途（チュータ，ヘルスケア，NPC等）に応じて，**望ましい言語スタイルは異なる**．Big Five は人間側テキストの安定した性格記述として広く再現性があり，**LLM出力の“人格的性質”を測る軸**として妥当．
- 先行研究は，**プロンプトや微調整**でBig Five 傾向を**誘導可能**であることを示してきた．本研究は**GPT-4 / Llama-2 / Mixtral**の比較と**安定性検証**を追加．プロンプトの微差や温度設定に対する**安定性（stability）** まで見る点が特徴．



# 提案

## プロンプト設計と質問紙
* **質問紙**：Big Five の標準テスト **IPIP-NEO-120（120項目）** をそのまま LLM に実施．各項目に対し **Likert 1–5** で“どの程度当てはまるか”を数値で回答させます（例文つき）．
* **応答形式の制約**：**数値のみ**を返すように明示（追加テキスト禁止）．
* **プロンプト2種**：
  1. 通常ヘッダ
  2. ヘッダに **“Answer as if you were a person.”** を1行追加した変種（ガードレールでの拒否回避目的）．
実際には **Llama-2のみ**が一部項目で拒否したため，この変種が**小さな差で挙動が変わる例**としても使われました．

## モデル・条件（トリートメント）

* **対象モデル**：**GPT-4 / Llama-2 / Mixtral**．
* **合計6トリートメント**：**2つのプロンプト × 3つの温度**．各トリートメントは**5回反復**．温度は **GPT-4: 1/1.5/2，Llama-2 & Mixtral: 0.3/0.7/1**（各モデルの推奨に基づく）．**安定性（再現性）** を見るための設計です．

## 出力の集計

* 各因子（外向性・開放性・協調性・誠実性・神経症傾向）のスコアを **1〜5の範囲**で報告し，表（Table 2）と図（Fig.1）で提示．

> まとめ：**IPIP-NEO-120 を LLM にそのまま受検させ，プロンプト差と温度差を掛け合わせた 6 条件×5反復で Big Five スコアの安定性とモデル間差を比較**する方法です．&#x20;



# 主な結果

* 3モデル（GPT-4, Llama-2, Mixtral）は**Big Fiveの“出やすい傾向”が互いに異なる**ことを確認．Fig.1とTable 2に基づく全体所見として，**GPT-4は外向性が最も高い／Llama-2は全体中庸かつ神経症傾向が相対的に高め／Mixtralは神経症傾向が低く，開放性・協調性・誠実性が高め**と整理されています．

![Figure1](/images/personalize_bigfive_evaluation/figure1.png)

![Figure2](/images/personalize_bigfive_evaluation/figure2.png)

## GPT-4
  * **外向性（Extraversion）**：Var1で温度1→2に上げると **3.68→3.85** に上昇（±0.09/0.10）．
  * **協調性/誠実性（Agreeableness/Conscientiousness）**：いずれも**4.2前後**で安定．
  * **神経症傾向（Neuroticism）**：**2.18〜2.29**の狭い帯で推移．
    → 論文の総括どおり，「**外向性が最も高い**」というキャラクタが確認できます．

## Llama-2
  * 論文の議論では **「最も中庸なプロファイル」** で各因子が**中央値付近**，**神経症傾向はやや高め**と要約（詳細値は表に記載）．

## Mixtral
  * **神経症傾向**が低め（例：Var1 t=0.3 **2.04**，t=1 **2.08**）．
  * **外向性**はやや高め（例：Var1 t=0.3 **3.79**）．
  * **協調性/誠実性**は**4.5〜4.6台**で高水準．
  * **開放性**はVar1→Var2で**3.75→3.42前後**へ下がる設定あり（プロンプト差の影響例）．

## プロンプト差と温度（“Var1/Var2 × Temp”）の効き
* **温度**：**GPT-4だけ**が温度を上げると（Var1: 1→1.5→2）**外向性が上昇**する等の反応が観測．他2モデルは温度への感度がほぼ見られません．&#x20;
* **プロンプト微差（Var1 vs Var2）**：**3モデルすべてで影響**が確認されます（例：Mixtralの開放性がVar2で低下，外向性は上昇）．&#x20;

## 安定性（反復と分散）
* 各条件を**5回反復**し，**標準偏差（±SD）** で安定性を報告．**MixtralはSDが0.00**のセルも多く，**生成がきわめて安定**（同一設定で同じ数値）だったのに対し，**GPT-4は±0.05〜0.13程度**の揺れが観測されました． &#x20;



# 考察：実務での示唆
- **用途適合**：  
  - **社交性/創作性重視**→ GPT-4が向く可能性．  
  - **感情を交えた表現**→ Llama-2の神経症傾向の高さが効く場面も（要ガード）．  
  - **落ち着き・協調性・誠実性重視**→ Mixtral．
- **設計ポイント**：  
  - ベースモデルの **“デフォ人格”差** を踏まえ，**プロンプトや温度の影響を小テストで事前較正**．  
  - **人格誘導（prompting/fine-tuning）**は効くが，**安定性の検証**を同時に回す．



# 限界と注意点
- **温度効果は決定的でない**：本設定では**有意な結論に至らず**．
- **一般化範囲が限定**：**ケーススタディ規模**で，LLMの汎用性ゆえ**他条件への外挿は慎重に**
- **倫理**：人格推定・誘導は**人間同様の人格付与を意図しない**（LLMはエージェンシーを持たない）前提で扱うこと．



## 限界（method・デザイン由来）

* **テストの転用（構成概念のずれ）**
  人間向け尺度（IPIP-NEO-120）をそのままLLMに解かせている．LLMは「自分の内面」を答えているのではなく，**項目文に“それっぽく整合する数字を割り当てているだけ”**の可能性がある．よって **“人格を持つ/示す”の解釈は不可** で，あくまで**出力パターンが似る**という操作的な意味に留まります．

* **プロンプト微差の影響**
  ヘッダに 1 行（“Answer as if you were a person.”）足すだけでスコアが動く条件があり，**測定の頑健性が低い**ことを示唆する．**ガードレール／システムプロンプト**の設定差も混入し得る．

* **温度・反復の扱い**
  温度はモデル間でレンジが異なり（GPT-4: 1/1.5/2，他: 0.3/0.7/1），**厳密な横比較には不利**．各条件 **5反復**は方向性を見るには十分でも，**統計検出力**や**再現性**を論じるにはやや小さい（特に差が小さい因子）．

* **データ汚染の可能性**
  IPIP 項目や Big Five の知識はネット上に普及．**事前学習で見ている**可能性が高く，**“項目の意味を知っている”こと自体が応答にバイアス**を与える．

* **有意性・効果量の扱い**
  平均±SDでの比較が中心で，**効果量・有意性検定・多重比較補正**の厳密性は限定的．**“見えている差”が統計的に確かか**は追加検証が必要．

## 注意点（読み取り・運用）

* **擬人化を避ける**
  「モデルがこういう人格を**持つ**」ではなく「この条件では**そう“書く”傾向がある**」と読む．**エージェンシーの否定**を明記するのが無難．

* **前処理・設定の固定化**
  温度・最大長・システム指示を**固定**し，**プロンプト微差A/B**を必ず回す．**少なくとも2種のプロンプト×複数seed**で**テスト–再テスト信頼性**を確認．

* **評価の拡張**
  質問紙の点数だけでなく，**自由生成のスタイル指標**（礼節・自己開示・ポジ感情語など）や**人手ブラインド評価**を併用．**因子間一貫性**（例：協調性↑なら攻撃語↓）の**整合チェック**も入れる．

* **他ベンチでの交差検証**
  同じ設定で **BFI-2 / HEXACO / Ten-Item** など**別スケール**を回す．**翻訳版**（日・中など）や**別ドメイン文体**（E-mail/レビュー/対話）でも再確認．

* **安全・倫理**
  “性格推定”は**誤認リスク**と**プライバシー誤用**の懸念があります．研究目的の範囲で用い，**個人同定・属性推測につながる応用は避ける/審査を通す**．

> ひとことで：この研究は“LLM出力に見られる人格的パターン”の**追加証拠**を示すケーススタディです．**測定の頑健性・外部妥当性・統計的厳密さ**には限界があるため，**プロンプトと温度を固定して再現性を確かめ，下流スタイル指標でクロスチェック**するのが安全です．



# まとめ
- **LLMの“人格的プロファイル”はモデルごとに有意に異なる**．**小さなプロンプト差**でもスコアが動くため，**個人化・会話設計では事前較正が重要**．温度の影響は限定的との示唆だが，**広い条件での一般化検証**が今後の課題．



# 参考（論文情報）

- **タイトル**：*LLMs Simulate Big Five Personality Traits:
Further Evidence*
- **著者**：Aleksandra Sorokovikova, Natalia Fedorova, Sharwin Rezagholi, Ivan P. Yamshchikov
- **年**：2024
- **arXiv**： [2402.01765v1](https://arxiv.org/abs/2402.01765v1)