---
title: "履歴を1つの埋め込みに凝縮して差し込むLLMに関する論文を一緒に読みましょう！"
emoji: "🦁"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["LLM", "Personalization", "UserEmbedding", "RAG", "LaMP"]
published: True
---


# Persona-Plug (PPlug) でLLMを個人化：履歴を1つの埋め込みに凝縮して差し込む
> この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと**同じ目線**で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！


# TL;DR
* **PPlug**は，ユーザ履歴全体を**1つの“個人埋め込み”** に凝縮し，**LLMの入力に前置**するだけで個人化を実現する枠組み．
* LLM本体のパラメータは固定のまま（**plug-and-play**）．**LaMPベンチマークの6タスク**で既存の**微調整型**や**リトリーバル型**を **+1.4%〜+35.8%** 上回った（相対）と報告．
* 計算負荷は**専用LLMを各ユーザごとに微調整**する方式より小さく，**履歴全体の“総体的な癖”** を掴めるのが強み．



# 背景

* **“みんな同じ出力”問題**
  汎用LLMは同一入力に対して誰に対しても似た応答を返しがちで，**主観や嗜好が効く場面**（文章作成・推薦・要約のトーンなど）では満足度を下げます．

* **先行アプローチ①：ユーザごと微調整**
  各ユーザ専用にLLMを**微調整（またはLoRAなどで適応）** する方法は直感的ですが，**計算・運用コストが高くスケールしない**のが難点．

* **先行アプローチ②：履歴リトリーバル（RAG系個人化）**
  ユーザ履歴から **“入力に関連する少数の例”** を取り出して**デモとして前置**する方式（LaMP系の標準パイプライン）．ただしこの方式は**ユーザの“全体的な文体・癖（holisticなスタイル）”**を取りこぼしやすく，履歴の**連続性を断ち切る**という根本課題が指摘されている．





# 提案（PPlug）
![Figure1](/images/persona_plug_personalization/figure1.png )
* **PPlugの立ち位置**
  リトリーバルが **“点の履歴”** に依存するのに対し，PPlugは **“履歴全体を入力依存で重み付けして1つの個人埋め込み”** に凝縮し，**LLMの先頭に差し込むだけ（LLMは凍結）**という**plug-and-play**設計を提案．これにより**全体像としてのスタイル・嗜好**を直接参照でき，**LLM本体の改変やユーザ別の再学習が不要**という運用上の利点も狙う．

- **実証**：LaMP（6タスク）で**PPlugが最良**．微調整（LoRA系）や高度化したRAG系（RSPG/ROPG）を**広く上回る**．



# 手法の概観
![Figure2](/images/persona_plug_personalization/figure2.png )
1. **User Behavior Encoder**：各履歴 \(h_{u,i}\) を**軽量エンコーダ**でベクトル化（実装例：BGE-base）．現在入力 \(x_u\) も別エンコーダで埋め込みに．
2. **Input-aware Personal Aggregator**：関連度 \(\propto x_u^\top h_{u,i}\) を**softmax重み**にして，すべての履歴を**投影MLP→加重和**し，**個人埋め込み \(P_u\)** を作成．
3. **LLMへの差し込み**：入力埋め込み列の先頭に **\[Instruction埋め込み I; 個人埋め込み \(P_u\)\]** を**前置**（LLMは**凍結**）．学習では **I / Enc\_input / Projector** のみ更新．



# データセットと評価（LaMP）

**LaMP（Language Model Personalization）の公開データ**を使っている．LaMPは“ユーザ履歴つき”の個人化ベンチで，各ユーザごとに時系列（過去→検証→テスト）で分割されたタスク群．
> 論文ではLaMPの6タスク（LaMP-6は非公開のため除外）を採用しています

* **対象タスク（6/7）**：LaMP-1（引用判定），LaMP-2（映画タグ付け），LaMP-3（商品レーティング），LaMP-4（ニュース見出し生成），LaMP-5（学術タイトル生成），LaMP-7（ツイート言い換え）．**時系列分割**で学習/検証/テスト．
* **指標**：LaMP-1/2は**Accuracy(+F1)**，LaMP-3は**MAE/RMSE（低いほど良）**，LaMP-4/5/7は**ROUGE-1/L**．

> 各タスクの **#Train/#Valid/#Test，平均入力長・出力長・履歴長** は付録Table 6にまとまっています



# 主な結果
![Figure3](/images/persona_plug_personalization/figure3.png )
* **総合**：**PPlugがほぼ全タスクで最良**．とくにLaMP-2/7（生成+分類）やLaMP-3（回帰）で大幅改善．**ベストRSPG-Post比で+1.4%〜+35.8%**（相対）．
* **微調整（FTP, LoRA系）**：**非個人化（Ad-hoc）比の改善が小**．ユーザごとに十分な履歴がないため学習が伸びにくいことを示唆．
![Figure4](/images/persona_plug_personalization/figure4.png )
* **アブレーション**：

  * **入力依存アグリゲータ**を平均化に置換→**精度低下**（それでもベースライン超え）．
  * **Instruction埋め込み**を除去→**やや低下**（個人埋め込みが主因，Iは**課題一般知識の分離**に効く）．

  ![Figure5](/images/persona_plug_personalization/figure5.png )
* **Retrievalとの統合**：PPlugに**1件の最も最も関連履歴**を**デモ**として併用すると，**LaMP-1/3/4/5/7でさらに上積み**（一方，LaMP-2は低下）．**粗粒度（PPlug）×細粒度（RAG）**の**相補**を確認．
* **履歴の“選択”は逆効果**：Top-4だけで個人埋め込みを作ると**悪化**．**全履歴の重み付き統合**が肝．
* **履歴の長さ**：長いほど改善傾向だが，**短くても堅牢**．



# 考察

* **Retrievalの弱点**（“入力に関連する断片”に偏る）に対し，PPlugは**入力条件付きの重み付け**で**全履歴**を取り込み，**“総体的な文体・嗜好”** を安定に反映．
* **各ユーザ専用LLMを作らない**ため**運用一体化**（単一LLM＋個人埋め込み）・**プライバシ**（**埋め込みだけ共有**でも成立）の実利が大きい．



# 限界と注意点

## 限界（研究としての射程）

* **凍結LLM前提**：LLM本体は固定（plug-and-play）．深い層までユーザ特化が必要な場面では**天井効果**の可能性．
* **粒度の制約**：履歴を**1ベクトル（粗粒度）**に凝縮．語彙／句レベルの微妙な嗜好や，会話の**瞬間的な方針切替**までは表現しにくい．
* **履歴依存**：履歴がきわめて短い／ノイズが多い場合の性能は限定的（論文では一定の頑健性は示唆，ただし十分な量がある方が良い）．
* **リトリーバル統合の簡素化**：併用は**1件デモ**前置の最小構成でのみ検証．**いつ・どれだけ取り出すか**の最適化や長文履歴でのスケール特性は今後課題．
* **可搬性の仮定**：履歴エンコーダ（BGE等）→LLM空間への**射影MLP**で整合を図る設計．**別LLM/別エンコーダ**への一般化は追加検証が必要．

## 注意点（実運用での勘所）

* **ドリフト管理**：嗜好は変化する．**定期的な再エンコード／重み更新**，古い履歴の減衰（時間重み）を設計に．
* **長大履歴の計算コスト**：PPlugは**全履歴の重み付き合成**が前提．履歴が非常に長い場合は**分割・バッチ化・近似検索**を併用．
* **品質監視**：分類（Acc/F1），回帰（MAE/RMSE），生成（ROUGE）など**標準指標＋人手評価**で\*\*個人化の“効きすぎ/弱すぎ”\*\*を継続監視．
* **干渉リスク**：**システムプロンプト／安全ガード**と個人埋め込みが干渉する可能性．**安全テスト**（毒性・幻覚・逸脱）を並走．



# 論文の主張まとめ

* **“全履歴×入力依存の重み付け”が肝**：Retrievalのように上位数件だけを使うのでなく，**全履歴を動的重みで統合**するから，ユーザの**総体的な文体・嗜好**を捉えられる．&#x20;

* **SOTA ベースラインを広く上回る**：LaMP の6タスクで，最良ベースライン（RSPG-Post）比 **+1.4%〜+35.8%（相対）**．個人化LLMの微調整型・RAG型の両方に対して優位．&#x20;

* **計算効率・運用性が高い**：履歴/入力用の**小型エンコーダ**のみ学習（例：\~220M，7B LLMの約**3.1%**規模）．LLM側は**パラメータ変更なし**で使い回せる．&#x20;

* **Retrievalの弱点を回避**：関連断片だけに偏ると“全体像”が欠落するという問題に対して，**ホリスティックな嗜好表現**で改善する設計だと主張．&#x20;

* **履歴の“選別”はむしろ悪化**：Top-Kの選択だけで個人埋め込みを作ると性能が落ち，**全履歴の加重統合**が有利．

* **履歴が短くても頑健，長いほど良い**：履歴が長いほど改善するが，短いユーザでも安定して効果が出る．



# 参考（論文情報）

- **タイトル**：*LLMs + Persona-Plug = Personalized LLMs*
- **著者**：Jiongnan Liu, Yutao Zhu, Shuting Wang, Xiaochi Wei, Erxue Min, Yu Lu, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou
- **年**：2024
- **arXiv**： [2409.11901v1](https://arxiv.org/abs/2409.11901v1)