---
title: "履歴を1つの埋め込みに凝縮して差し込むLLMに関する論文を一緒に読みましょう！"
emoji: "🦁"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["LLM", "Personalization", "UserEmbedding", "RAG", "LaMP"]
published: false
---


# Persona-Plug (PPlug) でLLMを個人化：履歴を1つの埋め込みに凝縮して差し込む
> この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと**同じ目線**で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！


# TL;DR
**PPlug**は、ユーザ履歴全体を**1つの“個人埋め込み”**に凝縮し、**LLMの入力に前置**するだけで個人化を実現する枠組み。LLM本体のパラメータは固定のまま（**plug-and-play**）。**LaMPベンチマークの6タスク**で既存の**微調整型**や**リトリーバル型**を**+1.4%〜+35.8%**上回った（相対）と報告。計算負荷は**専用LLMを各ユーザごとに微調整**する方式より小さく、**履歴全体の“総体的な癖”**を掴めるのが強み。



# 何が新しい？（貢献）
- **ユーザ履歴→1ベクトル**：各ユーザの全履歴を**エンコーダでベクトル化**し、**入力依存のアグリゲータ**で**1つの個人埋め込み**に統合。これを**LLM入力の先頭**に付加して出力を個人化。LLM自体は**固定**。
- **Retrievalより“全体像”**：従来の「関連履歴のみを取り出してデモ提示」では**全体的な文体・嗜好**を取りこぼしがち。PPlugは**全履歴を重み付きで統合**し、**包括的な個人像**で誘導。
- **実証**：LaMP（6タスク）で**PPlugが最良**。微調整（LoRA系）や高度化したRAG系（RSPG/ROPG）を**広く上回る**。



# 手法の概観（PPlug）
1. **User Behavior Encoder**：各履歴 \(h_{u,i}\) を**軽量エンコーダ**でベクトル化（実装例：BGE-base）。現在入力 \(x_u\) も別エンコーダで埋め込みに。
2. **Input-aware Personal Aggregator**：関連度 \(\propto x_u^\top h_{u,i}\) を**softmax重み**にして、すべての履歴を**投影MLP→加重和**し、**個人埋め込み \(P_u\)** を作成。
3. **LLMへの差し込み**：入力埋め込み列の先頭に **\[Instruction埋め込み I; 個人埋め込み \(P_u\)\]** を**前置**（LLMは**凍結**）。学習では **I / Enc\_input / Projector** のみ更新。



# データセットと評価（LaMP）

* **対象タスク（6/7）**：LaMP-1（引用判定）、LaMP-2（映画タグ付け）、LaMP-3（商品レーティング）、LaMP-4（ニュース見出し生成）、LaMP-5（学術タイトル生成）、LaMP-7（ツイート言い換え）。**時系列分割**で学習/検証/テスト。
* **指標**：LaMP-1/2は**Accuracy(+F1)**、LaMP-3は**MAE/RMSE（低いほど良）**、LaMP-4/5/7は**ROUGE-1/L**。



# 主な結果

* **総合**：**PPlugがほぼ全タスクで最良**。とくにLaMP-2/7（生成+分類）やLaMP-3（回帰）で大幅改善。**ベストRSPG-Post比で+1.4%〜+35.8%**（相対）。
* **微調整（FTP, LoRA系）**：**非個人化（Ad-hoc）比の改善が小**。ユーザごとに十分な履歴がないため学習が伸びにくいことを示唆。
* **アブレーション**：

  * **入力依存アグリゲータ**を平均化に置換→**精度低下**（それでもベースライン超え）。
  * **Instruction埋め込み**を除去→**やや低下**（個人埋め込みが主因、Iは**課題一般知識の分離**に効く）。
* **Retrievalとの統合**：PPlugに**1件の関連履歴**を**デモ**として併用すると、**LaMP-1/3/4/5/7でさらに上積み**（一方、LaMP-2は低下）。**粗粒度（PPlug）×細粒度（RAG）**の**相補**を確認。
* **履歴の“選択”は逆効果**：Top-4だけで個人埋め込みを作ると**悪化**。**全履歴の重み付き統合**が肝。
* **履歴の長さ**：長いほど改善傾向だが、**短くても堅牢**。



# 実装ノート

* **LLM**：主に **FlanT5-XXL (11B)**。**Llama-2-7B** などでも頑健に機能。**ビーム幅4**、入力量 **LLM=256 / Encoder=512** トークン。訓練は多くのタスクで**2エポック**。
* **Encoder**：BGE-base-en-v1.5（約**220M**）。PPlug全体で**軽量**かつ**エンドツーエンド**学習が可能。コード公開あり。



# 考察（なぜ効く？）

* **Retrievalの弱点**（“入力に関連する断片”に偏る）に対し、PPlugは**入力条件付きの重み付け**で**全履歴**を取り込み、\*\*“総体的な文体・嗜好”\*\*を安定に反映。
* **各ユーザ専用LLMを作らない**ため**運用一体化**（単一LLM＋個人埋め込み）・**プライバシ**（**埋め込みだけ共有**でも成立）の実利が大きい。



# 限界と今後

* **粒度**：本稿は**行動（履歴）単位**の表現。**語/句レベル**の頻出表現を組み込む拡張が課題。
* **粗×細の動的配分**：**個人埋め込み（粗）**と**RAGデモ（細）**を**いつ/どれだけ使うか**の最適化は未解決。



# 使いどころのヒント（運用目線）

* **まずはPPlug単体**（Iと入力依存アグリゲータあり）→**Abテスト**。
* 分類・回帰系（LaMP-1/2/3）では**履歴の質**、生成系（LaMP-4/5/7）では**文体の一貫性**をチェック。
* **履歴選別は慎重に**（“Top-Kだけ”は性能劣化の恐れ）。**RAG併用**は**一部タスクで上振れ**。

