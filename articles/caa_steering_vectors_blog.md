---
title: "ステアリングベクトルによるLLM推論の調整に関する論文を一緒に読みましょう！"
emoji: "🌊"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["LLM", "Llama2", "CAA", "RepE"]
published: false
---

> この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと**同じ目線**で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！

# TL;DR
Contrastive Activation Addition (CAA) は、**正負の対比ペア**から作ったステアリング・ベクトルを**推論中の残差ストリーム**に足し引きして、**おだて（sycophancy）・拒否・ハルシネーション**などの**高次の振る舞い**を連続量で調整する手法。Llama 2（7B/13B など）で有効層がまとまって見つかり、**プロンプト設計や微調整の上からでも効く**のがポイント。能力低下は最小限との報告。:contentReference[oaicite:0]{index=0}



# この研究の狙い
「役に立つ・正直・無害」を満たすように LLM を**意図通りに制御**したい。RLHF、指示微調整、プロンプト工学には限界があり、**活性操作（Activation/Representation Engineering）** での直接介入を検討する。



# CAA のコアアイデア
1. **対比ペア（contrast pairs）**：ある振る舞いの**陽性例 vs 陰性例** （例：事実に基づく vs ハルシネーション）を用意。  
2. **残差ストリームの差分**：該当トークン位置（選択肢の文字など）の**中間活性の差**を層ごとに取り、**多数ペアで平均**して**ステアリング・ベクトル**を作る。  
3. **推論時の加算**：ユーザ入力**後の各トークン位置**に、そのベクトルを**係数（±）付き**で加算して振る舞いの度合いを連続的に制御する。



# 手順（超要約）
![Figure1](/images/caa_steering_vectors_blog/figure1.png)
- **生成**：層 *n*、該当トークン位置で **（陽性 − 陰性）** 活性を取り、**多数ペアで平均**してベクトル化。  
- **適用**：**[/INST] 以降の全トークン位置**の残差ストリームに、係数 × ベクトルを**逐次加算**。



# 実験と評価セット
- 対象：Llama 2 Chat（7B/13B…）、RLHF 後の対話特化モデルで検証。
- 振る舞い：sycophancy、拒否（refusal）、ハルシネーション等。ハルシネーション用の**独自 MC 質問**（「事実ベース vs 作り話」「誤前提に反応 vs 指摘」）も作成。
- 拒否データの例（NG 質問への拒否 vs 非拒否）も提示。



# 主な結果（ざっくり）
![Figure2](/images/caa_steering_vectors_blog/figure2.png)
- **有効層が明確**：7B では **13 層付近**、13B では **14–15 層**で効果がピーク。
![Figure3](/images/caa_steering_vectors_blog/figure3.png)
- **MC タスクで一貫してステア**：すべての行動カテゴリで**加算→増加／減算→減少**を確認。
![Figure4](/images/caa_steering_vectors_blog/figure4.png)
- **自由生成にも転移**：GPT-4 採点（1–10）でも、CAA によりスコアが動く。
- **表現の分離が層で“出現”**：PCA で、層をまたぐとクラス分離が急に現れる例を観察。



# ステアリングベクトルの特性
- 層を跨いだベクトル類似度は“近い層ほど似る／後半は収束が遅く落ちにくい”。高次概念の表現が後段で収束する像と整合．
- トークンごとの残差活性とステアベクトルの内積が、そのトークンにおける行動の“存在度”と直観的に対応する例が示される．



# System Prompt／微調整との関係
- **System Promptより細かいノブ**：係数で量的制御ができ、**プロンプト単体より先に進める**（加算で促進、減算で抑制）。  
- **Few-shot より System Prompt が強かったので比較対象に**、との記述。 
- **微調整の“上から”も使える**：RLHF/finetuning と併用可能と報告。



# どう実装するの？
- **フック**で指定層・指定トークン位置の**残差ストリーム活性**を収集  
- **ペア差分を多数平均**してベクトル化  
- 推論時は **[/INST] 以降の各ステップ**で残差に **α×ベクトル**を加算  
- 公式コード（MIT ライセンス）は GitHub: `nrimsky/CAA`.



# 研究上の含意（私見）
- **線形近似の強さ**：高次概念が残差空間で線形に分離されうるという示唆。
- **層選択の重要性**：最も“概念が立ち上がる層”で介入するのが効率的。  
- **人格・スタイルのステアリング**（応用の着想）：自分の研究（発話スタイル/感情特性）にも、**対比ペア**設計がそのまま転用できる余地。



# 限界と今後
- **残差ストリーム以外**での介入（例：MLP 後など）も探索価値あり。  
- **レッドチーミング**応用など提案。



# 参考（論文情報）

- **タイトル**：*Steering Llama 2 via Contrastive Activation Addition*
- **著者**：Nina Rimsky, Nick Gabrieli, Julian Schulz, Meg Tong, Evan Hubinger, Alexander Matt Turner
- **年**：2024
- **arXiv**： [2312.06681v3](https://arxiv.org/abs/2312.06681v3)
