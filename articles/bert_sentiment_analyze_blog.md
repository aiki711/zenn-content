---
title: "BERT„É¢„Éá„É´„ÇíÊó•Êú¨Ë™û„É¨„Éì„É•„Éº„Åß„Éï„Ç°„Ç§„É≥„ÉÅ„É•„Éº„Éã„É≥„Ç∞„Åô„ÇãÔºöAmazon„É¨„Éì„É•„Éº √ó Êù±ÂåóBERT v3"
emoji: "üòé"
type: "tech"
topics: ["AI","NLP","BERT","Fine-tuning","Sentiment"]
published: true
---

# TL;DR
- **Êù±ÂåóBERT v3ÔºàSentencePieceÔºâ** „Çí‰Ωø„Å£„Å¶Êó•Êú¨Ë™ûAmazon„É¨„Éì„É•„ÉºÔºà3„ÇØ„É©„ÇπÔºöpos/neu/negÔºâ„Çí**ÊúÄÂ∞èÊßãÊàê**„ÅßÂ≠¶Áøí„ÉªË©ï‰æ°  
- Âá∫Âäõ„ÅØ **Accuracy / Precision / Recall / F1ÔºàMacroÔºâ/ Confusion Matrix**„ÄÇË™§ÂàÜÈ°û„ÅÆÈ´òÁ¢∫‰ø°‰æã„ÇÇËá™Âãï„ÅßÊäΩÂá∫  
- HPCÔºàOpenPBS / A40Ôºâ„Åß„ÇÇ**„Åù„ÅÆ„Åæ„ÅæÂÜçÁèæ**„Åß„Åç„Çã„Çà„ÅÜ„Å´„ÄÅ„Ç≠„É£„ÉÉ„Ç∑„É•Âõ∫ÂÆö„Éª„Éò„ÉÉ„Éâ„É¨„ÇπÊèèÁîª„ÉªPBS„Ç∏„Éß„Éñ‰æã„ÇíÂêåÊ¢±  
- Transformers „ÅÆ**„Éê„Éº„Ç∏„Éß„É≥Â∑ÆÔºà`evaluation_strategy` vs `eval_strategy`Ôºâ**„Å´„ÇÇËÄê„Åà„ÇãÂÆâÂÖ®„É¨„Ç∑„Éî„ÇíÊèêÁ§∫


# ËÉåÊôØ„Å®ÁõÆÁöÑ
„Çº„É≠„Ç∑„Éß„ÉÉ„Éà„ÅÆË©ï‰æ°Á≥ª„Å´Á∂ö„ÅÑ„Å¶ÔºàÂà•Ë®ò‰∫ãÂèÇÁÖßÔºâÔºå‰ªäÂõû„ÅØ **‰∫ãÂâçÂ≠¶ÁøíÊ∏à„ÅøBERT„ÅÆ„Éï„Ç°„Ç§„É≥„ÉÅ„É•„Éº„Éã„É≥„Ç∞**„ÅßÊó•Êú¨Ë™û„ÅÆÊÑüÊÉÖÂàÜÈ°û„Çí„ÇÑ„Å£„Å¶„Åø„ÇãÔºé  
ÂÜçÁèæÊÄß„ÇíÈáçË¶ñ„ÅóÔºå**Áí∞Â¢É‚Üí„Éá„Éº„Çø‚ÜíÂâçÂá¶ÁêÜ‚ÜíÂ≠¶Áøí‚ÜíÂèØË¶ñÂåñ‚ÜíË©ï‰æ°‚Üí„Ç®„É©„ÉºÂàÜÊûê**„ÅåÂ¥©„Çå„Å™„ÅÑ‚ÄúÊúÄÁü≠ÂãïÁ∑ö‚Äù„ÇíÊÑèË≠ò„Åó„ÅüÔºéHPCÁí∞Â¢É„Åß„ÇÇ„Éï„Ç©„É´„ÉÄÊ±öÊüì„Åõ„Åö„Å´Âãï„Åè„Çà„ÅÜÔºå**‰ΩúÊ•≠„Éá„Ç£„É¨„ÇØ„Éà„É™Áõ¥‰∏ã**„Å´ÊàêÊûúÁâ©„Å®„Ç≠„É£„ÉÉ„Ç∑„É•„ÇíÂõ∫ÂÆö„Åó„Å¶„ÅÑ„ÇãÔºé


# ÂÆüÈ®ìË®≠ÂÆöÔºà„Åñ„Å£„Åè„ÇäÔºâ
- **„Éá„Éº„Çø**ÔºöSetFit/amazon_reviews_multi_jaÔºàÊòü1‚Äì5 ‚Üí 1‚Äì2=neg, 3=neu, 4‚Äì5=pos „ÅÆ3ÂÄ§ÂåñÔºâ
- **„É¢„Éá„É´**Ôºö`cl-tohoku/bert-base-japanese-v3`ÔºàSentencePiece„ÄÇ**fugashi‰∏çË¶Å**Ôºâ
- **Ë©ï‰æ°**ÔºöAccuracy / Precision / Recall / F1ÔºàMacroÔºâÔºãÊ∑∑ÂêåË°åÂàó„ÄÅË™§ÂàÜÈ°û„Éà„ÉÉ„Éó‰æã„ÅÆ„ÉÄ„É≥„Éó
- **Âá∫ÂäõÂÖà**Ôºö`./figs`, `./reports`, `./outputs-ja-bert`, `./.cache`, `./tmp`Ôºà„Åô„Åπ„Å¶**„Ç´„É¨„É≥„ÉàÁõ¥‰∏ã**Ôºâ


# ÂÜçÁèæÊâãÈ†ÜÔºàÊúÄÁü≠Ôºâ
## 1) Áí∞Â¢ÉÊßãÁØâÔºàconda „ÅÆ‰æãÔºâ
```bash
conda create -n nlp-sft python=3.10 -y
conda activate nlp-sft

# GPU Áâà PyTorchÔºàCUDA 12.4 „ÅÆ‰æã„ÄÇCPU„ÅÆ„Åø„Å™„Çâ index-url „Çí cpu „Å´Ôºâ
python -m pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio

# NLP‰∏ÄÂºè
python -m pip install -U "transformers>=4.41" "datasets>=2.19" "accelerate>=0.30" \
  evaluate scikit-learn matplotlib sentencepiece "protobuf<5"
````

## 2) Â≠¶Áøí„Çπ„ÇØ„É™„Éó„ÉàÔºà„Åù„ÅÆ„Åæ„Åæ‰øùÂ≠ò„Åó„Å¶ÂÆüË°åÔºâ

> „Éï„Ç°„Ç§„É´ÂêçÔºö`run_bert_amazon.py`

```python
import os, matplotlib
matplotlib.use("Agg")  # „Éò„ÉÉ„Éâ„É¨„ÇπÊèèÁîª

# ====== ‰ΩúÊ•≠„Éá„Ç£„É¨„ÇØ„Éà„É™Áõ¥‰∏ã„Å´Âõ∫ÂÆö ======
BASE = os.path.abspath(os.getcwd())
os.environ.setdefault("HF_HOME",            os.path.join(BASE, ".cache", "hf"))
os.environ.setdefault("HF_HUB_CACHE",       os.path.join(BASE, ".cache", "hub"))
os.environ.setdefault("TRANSFORMERS_CACHE", os.path.join(BASE, ".cache", "transformers"))
os.environ.setdefault("HF_DATASETS_CACHE",  os.path.join(BASE, ".cache", "datasets"))
os.environ.setdefault("TMPDIR",             os.path.join(BASE, "tmp"))
for d in [os.environ["HF_HOME"], os.environ["HF_HUB_CACHE"], os.environ["TRANSFORMERS_CACHE"],
          os.environ["HF_DATASETS_CACHE"], os.environ["TMPDIR"]]:
    os.makedirs(d, exist_ok=True)

FIGS_DIR, REPORTS_DIR = os.path.join(BASE, "figs"), os.path.join(BASE, "reports")
OUT_DIR = os.path.join(BASE, "outputs-ja-bert")
os.makedirs(FIGS_DIR, exist_ok=True); os.makedirs(REPORTS_DIR, exist_ok=True)

# ====== „Éá„Éº„Çø ======
from datasets import load_dataset
ds = load_dataset("SetFit/amazon_reviews_multi_ja", cache_dir=os.environ["HF_DATASETS_CACHE"])

def map_label(star):
    star = int(star)
    return 0 if star <= 2 else (1 if star == 3 else 2)  # 0:NEG 1:NEU 2:POS

for split in ds:
    if "text" in ds[split].features:
        ds[split] = ds[split].rename_columns({"text":"review"})
    if "label" in ds[split].features and "star" not in ds[split].features:
        ds[split] = ds[split].rename_columns({"label":"star"})
    ds[split] = ds[split].map(lambda ex: {"label": map_label(ex["star"])})

# ====== EDAÔºàÈï∑„ÅïÂàÜÂ∏ÉÔºâ ======
import numpy as np, matplotlib.pyplot as plt
lengths = [len(ex["review"]) for ex in ds["train"]]
plt.figure(); plt.hist(lengths, bins=50)
plt.title("Review length distribution (train)"); plt.xlabel("chars"); plt.ylabel("count")
plt.tight_layout(); plt.savefig(os.path.join(FIGS_DIR, "length_hist.png"), dpi=150); plt.close()

# ====== „Éà„Éº„ÇØ„Éä„Ç§„Ç∫ ======
from transformers import AutoTokenizer, DataCollatorWithPadding
MODEL_NAME = "cl-tohoku/bert-base-japanese-v3"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False, word_tokenizer_type="basic")  # MeCabÁµåË∑Ø„Çí‰Ωø„Çè„Å™„ÅÑ

def tok(batch):
    return tokenizer(batch["review"], truncation=True, padding=False, max_length=256)

remove_cols = [c for c in ds["train"].column_names if c not in ["label"]]
tokenized = ds.map(tok, batched=True, remove_columns=remove_cols)
collator = DataCollatorWithPadding(tokenizer=tokenizer)

if "validation" not in tokenized:
    sp = tokenized["train"].train_test_split(test_size=0.2, seed=42)
    tokenized = {"train": sp["train"], "validation": sp["test"],
                 "test": ds["test"].map(tok, batched=True, remove_columns=remove_cols)}

# ====== Â≠¶Áøí ======
from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer
import evaluate

id2label = {0:"NEG",1:"NEU",2:"POS"}; label2id = {v:k for k,v in id2label.items()}
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3, id2label=id2label, label2id=label2id)

acc = evaluate.load("accuracy"); prec = evaluate.load("precision"); rec = evaluate.load("recall"); f1 = evaluate.load("f1")
def compute_metrics(eval_pred):
    import numpy as np
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)
    return {
        "accuracy": acc.compute(predictions=preds, references=labels)["accuracy"],
        "precision_macro": prec.compute(predictions=preds, references=labels, average="macro")["precision"],
        "recall_macro": rec.compute(predictions=preds, references=labels, average="macro")["recall"],
        "f1_macro": f1.compute(predictions=preds, references=labels, average="macro")["f1"],
    }

# ‚Üê TransformersÁâà„ÅÆÈÅï„ÅÑ„Å´ÂØæÂøúÔºàevaluation_strategy / eval_strategyÔºâ
import inspect
ta_params = set(inspect.signature(TrainingArguments.__init__).parameters)
eval_key = "evaluation_strategy" if "evaluation_strategy" in ta_params else ("eval_strategy" if "eval_strategy" in ta_params else None)
save_key = "save_strategy" if "save_strategy" in ta_params else None

kwargs = dict(
    output_dir=OUT_DIR, per_device_train_batch_size=16, per_device_eval_batch_size=16,
    learning_rate=2e-5, num_train_epochs=3, warmup_ratio=0.1, weight_decay=0.01,
    logging_steps=50, seed=42, dataloader_num_workers=2,
)
if eval_key: kwargs[eval_key] = "epoch"
if save_key: kwargs[save_key] = "epoch"
else:
    kwargs["save_steps"] = 500
    if eval_key:
        kwargs[eval_key] = "steps"
        if "eval_steps" in ta_params: kwargs["eval_steps"] = 500
if "report_to" in ta_params: kwargs["report_to"] = "none"
if ("load_best_model_at_end" in ta_params) and eval_key and ((save_key and kwargs.get(save_key)==kwargs.get(eval_key)) or (not save_key and kwargs.get(eval_key)=="steps")):
    kwargs["load_best_model_at_end"] = True
    if "metric_for_best_model" in ta_params: kwargs["metric_for_best_model"] = "f1_macro"
    if "greater_is_better" in ta_params: kwargs["greater_is_better"] = True

args = TrainingArguments(**kwargs)

trainer = Trainer(
    model=model, args=args,
    train_dataset=tokenized["train"], eval_dataset=tokenized["validation"],
    tokenizer=tokenizer, data_collator=collator, compute_metrics=compute_metrics,
)
trainer.train()

# ====== ÂèØË¶ñÂåñ„ÉªË©ï‰æ°„ÉªË™§Â∑ÆÂàÜÊûê ======
hist = trainer.state.log_history
train_loss = [h["loss"] for h in hist if "loss" in h and "epoch" in h]
eval_loss  = [h["eval_loss"] for h in hist if "eval_loss" in h]
et, ee = [h["epoch"] for h in hist if "loss" in h and "epoch" in h],[h["epoch"] for h in hist if "eval_loss" in h]
plt.figure(); plt.plot(et, train_loss, label="train loss"); plt.plot(ee, eval_loss, label="eval loss")
plt.legend(); plt.xlabel("epoch"); plt.title("Loss curves"); plt.tight_layout()
plt.savefig(os.path.join(FIGS_DIR, "loss_curves.png"), dpi=150); plt.close()

test_metrics = trainer.evaluate(tokenized["test"])
print("=== TEST METRICS ==="); print(test_metrics)

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
preds = trainer.predict(tokenized["test"])
y_true = preds.label_ids; y_pred = preds.predictions.argmax(axis=-1)
report = classification_report(y_true, y_pred, target_names=["NEG","NEU","POS"])
cm = confusion_matrix(y_true, y_pred)
with open(os.path.join(REPORTS_DIR, "classification_report.txt"), "w", encoding="utf-8") as f:
    f.write(str(test_metrics) + "\n\n" + report)

plt.figure(); plt.imshow(cm, interpolation="nearest"); plt.title("Confusion Matrix"); plt.colorbar()
plt.xticks([0,1,2], ["NEG","NEU","POS"]); plt.yticks([0,1,2], ["NEG","NEU","POS"])
plt.tight_layout(); plt.savefig(os.path.join(FIGS_DIR, "confusion_matrix.png"), dpi=150); plt.close()

# È´òÁ¢∫‰ø°„ÅßË™§„Å£„Åü‰æã„Çí5‰ª∂
probs = preds.predictions - preds.predictions.max(axis=1, keepdims=True)
probs = np.exp(probs)/np.exp(probs).sum(axis=1, keepdims=True)
conf = probs.max(axis=1); wrong = np.where(y_true!=y_pred)[0]
top_wrong = wrong[np.argsort(conf[wrong])[::-1][:5]]
for i in top_wrong:
    print(f"[gt={['NEG','NEU','POS'][y_true[i]]}, pred={['NEG','NEU','POS'][y_pred[i]]}, conf={conf[i]:.2f}]")
```

## 3) ÂÆüË°å

```bash
python run_bert_amazon.py
# ./figs, ./reports, ./outputs-ja-bert, ./.cache, ./tmp „Åå‰ΩúÊàê„Åï„Çå„Åæ„Åô
```


# ‰ª£Ë°®ÁöÑ„Å™Â§±Êïó„Å®ÂØæÂá¶

* **`fugashi` „ÅåÁÑ°„ÅÑ/MeCabÁ≥ª„ÅßËêΩ„Å°„Çã**
  ‚Üí `cl-tohoku/bert-base-japanese-v3` „Çí‰Ωø„ÅÑÔºå`AutoTokenizer(..., use_fast=False, word_tokenizer_type="basic")` „Åß **MeCabÁµåË∑Ø„ÇíÊòéÁ§∫ÂõûÈÅø**Ôºé`sentencepiece` „ÅÆ„Åø„ÅßOKÔºé
* **`protobuf` „ÅÆ ImportError**
  ‚Üí `python -m pip install -U "protobuf<5"`ÔºàTransformers‰∫íÊèõ„ÅÆ„Åü„ÇÅ `<5` Êé®Â•®ÔºâÔºé
* **Transformers „ÅÆÂºïÊï∞ÂêçÈÅï„ÅÑ„ÅßËêΩ„Å°„Çã**Ôºà`evaluation_strategy` vs `eval_strategy`Ôºâ
  ‚Üí ‰∏äË®ò„Çπ„ÇØ„É™„Éó„Éà„ÅÆ **ÂºïÊï∞Ëá™ÂãïÊ§úÂá∫**„ÅßÂê∏ÂèéÔºéÂõ∫ÂÆö„ÅßÊõ∏„ÅèÂ†¥Âêà„ÅØÔºåÁí∞Â¢É„Å´Âêà„Çè„Åõ„Å¶**„Å©„Å°„Çâ„Åã**„ÇíÊåáÂÆöÔºé
* **„Éï„Ç©„É´„ÉÄ„Åå„Éê„É©„Åë„Çã**
  ‚Üí „Çπ„ÇØ„É™„Éó„ÉàÂÜíÈ†≠„ÅÆ **Áí∞Â¢ÉÂ§âÊï∞„Å®‰øùÂ≠òÂÖà„ÅÆÂõ∫ÂÆö**„ÇíÁ¢∫Ë™çÔºà`.cache/` „Å® `tmp/` „Çí„Ç´„É¨„É≥„ÉàÁõ¥‰∏ãÔºâÔºé
* **„Éò„ÉÉ„Éâ„É¨„Çπ„Åß `plt.show()` „ÅåË©∞„Åæ„Çã**
  ‚Üí `matplotlib.use("Agg")` Ôºã `savefig` „Å∏Ôºé


# HPCÔºàOpenPBSÔºâ„Åß„ÅÆÂÆüË°å‰æã

ÊúÄÂ∞è„ÅÆ„Ç∏„Éß„Éñ„Çπ„ÇØ„É™„Éó„ÉàÔºàÁí∞Â¢ÉÂêç„Éª„Ç≠„É•„ÉºÂêç„ÉªGPUË≥áÊ∫êÂêç„ÅØ„ÇØ„É©„Çπ„Çø„Éº„Å´Âêà„Çè„Åõ„Å¶Â§âÊõ¥Ôºâ

```bash
#!/bin/bash
# ====== OpenPBS/PBS Pro (pbs_version 20.x) ======
# Job metadata
#PBS -N sft_bert_ja
#PBS -q GPU-1
# Resource request (OpenPBS 20.x 'select' syntax)
# 1 chunk: 8 CPU cores, 1 GPU, 32GB RAM
# If your site names the GPU resource differently, change ngpus=1 to gpu=1 or gres=1 accordingly.
#PBS -l select=1:ncpus=8:ngpus=1:mem=32gb
# Place policy (optional): pack tasks on a single node, exclusively
#PBS -l place=pack:excl
# Walltime
#PBS -l walltime=12:00:00
# Join stdout/stderr
#PBS -j oe

set -euo pipefail

echo "===[ENV]============================================="
date
echo "PBS version: ${PBS_VERSION:-unknown}  Job ID: ${PBS_JOBID:-N/A}"
echo "Job Name: ${PBS_JOBNAME:-N/A}"
echo "Work dir: ${PBS_O_WORKDIR:-$(pwd)}"
echo "Node: $(hostname)"
echo "======================================================"

# Go to submission directory
cd "${PBS_O_WORKDIR:-$PWD}"

# --- Modules (site-specific; uncomment if needed) ---
# module load cuda/12.1
# module load anaconda/2024.02

# --- Activate environment (conda preferred; venv fallback) ---
if [ -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; then
  source "$HOME/miniconda3/etc/profile.d/conda.sh"
elif [ -f "$HOME/anaconda3/etc/profile.d/conda.sh" ]; then
  source "$HOME/anaconda3/etc/profile.d/conda.sh"
fi
conda activate nlp-sft 2>/dev/null || true
# Or, if you used venv:
# source .venv/bin/activate

# --- Per-job caches to reduce $HOME I/O ---
BASE="${PBS_O_WORKDIR:-$PWD}"
mkdir -p "$BASE/.cache/hf" "$BASE/.cache/hub" "$BASE/.cache/transformers" "$BASE/.cache/datasets" "$BASE/tmp"
export HF_HOME="$BASE/.cache/hf" HF_HUB_CACHE="$BASE/.cache/hub" TRANSFORMERS_CACHE="$BASE/.cache/transformers" HF_DATASETS_CACHE="$BASE/.cache/datasets"
export TMPDIR="$BASE/tmp"


echo "===[RUNTIME DIAGNOSTICS]=============================="
nvidia-smi || true
python - <<'PY'
import sys, torch
print("Python:", sys.version.replace("\n"," ").strip())
print("Torch:", torch.__version__, "CUDA available:", torch.cuda.is_available())
try:
    import transformers, datasets
    print("Transformers:", transformers.__version__)
    print("Datasets:", datasets.__version__)
except Exception as e:
    print("Transformers/Datasets import issue:", e)
PY
echo "======================================================"

# ---- RUN: replace with your training script & args ----
# Example (fits the fine-tuning assignment):
python run_bert_amazon.py \
  --model_name cl-tohoku/bert-base-japanese-v3 \
  --epochs 3 \
  --batch_size 16 \
  --lr 2e-5 \
  --max_length 256 \
  --seed 42

echo "Done."

```

ÈÄÅ‰ø°Ôºö

```bash
qsub train_sft_openpbs20.pbs
```


# ÁµêÊûú„ÅÆË¶ãÊñπÔºà„Åæ„Åö„Åì„Åì„Çí„ÉÅ„Çß„ÉÉ„ÇØÔºâ

1. `reports/classification_report.txt`ÔºöAccuracy / Macro-F1„ÄÅ„ÇØ„É©„ÇπÂà•ÊåáÊ®ô
2. `figs/confusion_matrix.png`Ôºö„Å©„ÅÆ„ÇØ„É©„Çπ„ÅßÂèñ„ÇäÈÅï„Åà„ÅåÂ§ö„ÅÑ„Åã
3. Ë™§ÂàÜÈ°û„É≠„Ç∞ÔºàÊ®ôÊ∫ñÂá∫Âäõ„ÅÆ5‰ª∂ÔºâÔºö**Á¢∫‰ø°Â∫¶„ÅåÈ´ò„ÅÑ„ÅÆ„Å´Ë™§„Çä**„ÅÆ„Çµ„É≥„Éó„É´„ÇíË™≠„ÇÄ

# ÂÆüÈ®ìÁµêÊûú

```
              precision    recall  f1-score   support

         NEG       0.89      0.90      0.89      3000
         NEU       0.52      0.46      0.49      1000
         POS       0.67      0.73      0.70      1000

    accuracy                           0.78      5000
   macro avg       0.69      0.69      0.69      5000
weighted avg       0.77      0.78      0.77      5000
```

* ÂÖ®‰ΩìÔºöAccuracy 0.78ÔºéÂ§öÊï∞Ê¥æÔºàNEG=60%Ôºâ„Å´‚ÄúÂØÑ„Åõ„Çã„Å†„Åë‚Äù„ÅÆ 0.60 „ÅØÂçÅÂàÜË∂Ö„Åà„Å¶„ÅÑ„Å¶ÔºåÂ≠¶Áøí„ÅØÂäπ„ÅÑ„Å¶„ÅÑ„ÇãÔºé

* NEGÔºöP/R/F1 ‚âà 0.89/0.90/0.89 „Å®Â†Ö„ÅÑÔºàÂèñ„Çä„Åì„Åº„ÅóÂ∞ëÔºâÔºé

* POSÔºöF1=0.70 „Åß„Åæ„Åö„Åæ„ÅöÔºé

* NEUÔºöF1=0.49 „Å®Âº±„ÅÑÔºéPrecision 0.52ÔºèRecall 0.46 ‚Üí „ÄåÂÆüÈöõ„Å´NEU„Å™„ÅÆ„ÇíÂçäÂàÜ‰ª•‰∏äÂèñ„ÇäÈÄÉ„Åô„Äç„ÅóÔºå„ÄåNEU„Å®Âà§ÂÆö„Åó„Åü„ÇÇ„ÅÆ„ÅÆÁ¥ÑÂçäÂàÜ„ÅØ‰ªñ„ÇØ„É©„Çπ„Äç„ÄÇ

* ‰∏çÂùáË°°„ÅÆÂΩ±ÈüøÔºö„Çµ„Éù„Éº„Éà„Åå 3000/1000/1000Ôºà3:1:1ÔºâÔºéweighted avg „Åå Accuracy „Å®Ëøë„ÅÑ„ÅÆ„ÅØÔºåÂ§öÊï∞Ê¥æNEG„ÅÆÂá∫Êù•„ÅåÂÖ®‰Ωì„ÇíÊäº„Åó‰∏ä„Åí„Å¶„ÅÑ„Çã„Çµ„Ç§„É≥Ôºémacro avg=0.69 „Åå‚Äú„Éê„É©„É≥„ÇπË©ï‰æ°‚ÄùÔºé


# „Åä„Çè„Çä„Å´

„Çº„É≠„Ç∑„Éß„ÉÉ„Éà„Å´ÊØî„ÅπÔºåBERT„ÅÆ„Çø„Çπ„ÇØÂæÆË™øÊï¥„ÅØ **„Çà„ÇäÂÆâÂÆö„Åó„ÅüÂÜçÁèæÊÄß** „Å® **ÁèæÂ†¥ÈÅãÁî®„Å´Ëøë„ÅÑÂ≠¶Áøí/Ë©ï‰æ°„ÅÆÂûã**„ÇíÊèê‰æõ„Åô„ÇãÔºé
‰∏ÄÊñπ„ÅßÔºå„Éê„Éº„Ç∏„Éß„É≥Â∑Æ„ÉªÂΩ¢ÊÖãÁ¥†‰æùÂ≠ò„ÉªHPC‰∫ãÊÉÖ„Å™„Å©„ÅÆ**ÈùûÊú¨Ë≥™ÁöÑ„Å™Ê≤º**„ÅåÊΩú„ÇÄ„ÅÆ„ÇÇ‰∫ãÂÆüÔºé„Åì„ÅÆË®ò‰∫ã„Åß„ÅØ„Åù„Çå„Çâ„ÇíÂõûÈÅø„Åó„Å¶Ôºå**Âãï„Åè„Éó„É≠„Ç∞„É©„É†„Å´„Åô„Çã**„Åì„Å®„ÇíÁõÆÊ®ô„Å´„Åó„Åæ„Åó„ÅüÔºé
Ê¨°„ÅØ mBERT „ÇÑËªΩÈáè„É¢„Éá„É´ÔºàDistilBERTÔºâ„Å®„ÅÆ**ÈÄüÂ∫¶„ÉªÁ≤æÂ∫¶„Éà„É¨„Éº„Éâ„Ç™„Éï**ÔºåÂ∞ëÈáèËøΩÂä†Â≠¶ÁøíÔºàLoRAÁ≠âÔºâ„Åß„ÅÆ**ÊîπÂñÑÂπÖ**„ÇíÊ§úË®º„Åó„Å¶„ÅÑ„Åç„Åü„ÅÑÔºé
